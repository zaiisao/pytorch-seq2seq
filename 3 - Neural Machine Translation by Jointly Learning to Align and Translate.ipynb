{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gL8FU4Z7-Hw"
      },
      "source": [
        "# 3 - Neural Machine Translation by Jointly Learning to Align and Translate\n",
        "\n",
        "In this third notebook on sequence-to-sequence models using PyTorch and TorchText, we'll be implementing the model from [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473). This model achives our best perplexity yet, ~27 compared to ~34 for the previous model.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "As a reminder, here is the general encoder-decoder model:\n",
        "\n",
        "![](https://github.com/zaiisao/pytorch-seq2seq/blob/master/assets/seq2seq1.png?raw=1)\n",
        "\n",
        "In the previous model, our architecture was set-up in a way to reduce \"information compression\" by explicitly passing the context vector, $z$, to the decoder at every time-step and by passing both the context vector and embedded input word, $d(y_t)$, along with the hidden state, $s_t$, to the linear layer, $f$, to make a prediction.\n",
        "\n",
        "![](https://github.com/zaiisao/pytorch-seq2seq/blob/master/assets/seq2seq7.png?raw=1)\n",
        "\n",
        "Even though we have reduced some of this compression, our context vector still needs to contain all of the information about the source sentence. The model implemented in this notebook avoids this compression by allowing the decoder to look at the entire source sentence (via its hidden states) at each decoding step! How does it do this? It uses *attention*. \n",
        "\n",
        "Attention works by first, calculating an attention vector, $a$, that is the length of the source sentence. The attention vector has the property that each element is between 0 and 1, and the entire vector sums to 1. We then calculate a weighted sum of our source sentence hidden states, $H$, to get a weighted source vector, $w$. \n",
        "\n",
        "$$w = \\sum_{i}a_ih_i$$\n",
        "\n",
        "We calculate a new weighted source vector every time-step when decoding, using it as input to our decoder RNN as well as the linear layer to make a prediction. We'll explain how to do all of this during the tutorial.\n",
        "\n",
        "## Preparing Data\n",
        "\n",
        "Again, the preparation is similar to last time.\n",
        "\n",
        "First we import all the required modules."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BdYCZ6tvDjx",
        "outputId": "c1780fee-bcd7-4439-843f-ce7b2c53ac65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp39-cp39-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext==0.10.0) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext==0.10.0) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext==0.10.0) (1.22.4)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp39-cp39-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.4/831.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.10.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.10.0) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.10.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.10.0) (3.4)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.1\n",
            "    Uninstalling torchtext-0.15.1:\n",
            "      Successfully uninstalled torchtext-0.15.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzQpY2UHxnG5",
        "outputId": "428c143e-5f67-4209-fe38-681e3e776948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-08 12:11:32.877526: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.6.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "2023-04-08 12:11:45.335436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n",
            "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting de-core-news-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.5.0/de_core_news_sm-3.5.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from de-core-news-sm==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (67.6.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.1.2)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma1T6VqQ7-Hy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InhY07Ib7-Hz"
      },
      "source": [
        "Set the random seeds for reproducability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7paHlOqe7-Hz"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY4tj1xj7-Hz"
      },
      "source": [
        "Load the German and English spaCy models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqej5OAD7-Hz"
      },
      "outputs": [],
      "source": [
        "# JA: What is spaCy? From website:\n",
        "# spaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python.\n",
        "# It’s designed specifically for production use and helps you build applications that process and\n",
        "# “understand” large volumes of text. It can be used to build information extraction or natural\n",
        "# language understanding systems.\n",
        "#\n",
        "# The following loads the German and English models from spaCy, each of which consist of the\n",
        "# tokenizer, tagger, parser and NER (named entity recognition).\n",
        "#\n",
        "# NER identifies, categorizes and extracts the most important pieces of information from\n",
        "# unstructured text without requiring time-consuming human analysis. It's particularly useful for\n",
        "# quickly extracting key information from large amounts of data because it automates the\n",
        "# extraction process. https://www.techtarget.com/whatis/definition/named-entity-recognition-NER\n",
        "\n",
        "spacy_de = spacy.load('de_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FeXDNF97-H0"
      },
      "source": [
        "We create the tokenizers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdDGhfzm7-H0"
      },
      "outputs": [],
      "source": [
        "# JA: What do tokenizers do?\n",
        "# Given some text, it must be split into smaller bits of text like words in a sentence. These are\n",
        "# referred to as tokens. Some sort of mechanism that turns larger groups of text into so-callled\n",
        "# tokens are thus referred to as tokenizers\n",
        "#\n",
        "# When the text values in each tokenize function are printed, here is the partial output:\n",
        "#\n",
        "# tokenize_de text: Ein Mann geht auf einem Feldweg.\n",
        "# tokenize_en text: A man walking on a dirt road.\n",
        "# tokenize_de text: Eine Gruppe aus sieben Frauen steht in einem Gewässer.\n",
        "# tokenize_en text: A group of seven women are standing in a body of water.\n",
        "# tokenize_de text: Ein junger Asiate sitzt hinter einem Schackbrett und wartet auf seinen Gegenspieler.\n",
        "# tokenize_en text: A young Asian man sits behind a set chessboard waiting for the other player to arrive.\n",
        "# tokenize_de text: Kinder beim Sackhüpfen bei einem geselligen Beisammensein.\n",
        "# tokenize_en text: Children are competing in a potato sack race at an outdoor social gathering.\n",
        "# tokenize_de text: Drei Personen machen Liegestütze.\n",
        "# tokenize_en text: Three people doing push ups.\n",
        "# tokenize_de text: Männer spielen in einem Park auf unterschiedlichen Musikinstrumenten.\n",
        "# tokenize_en text: Men are playing different musical instruments in a park.\n",
        "# tokenize_de text: Ein Mann und eine Frau beim Tanzen.\n",
        "# tokenize_en text: A man and woman is dancing.\n",
        "#\n",
        "# Notably, these are pairs (the same sentences written in English and German).\n",
        "\n",
        "def tokenize_de(text):\n",
        "    \"\"\"\n",
        "    Tokenizes German text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    # print(f\"tokenize_de text: {text}\")\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    # print(f\"tokenize_en text: {text}\")\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewZY70Cm7-H0"
      },
      "source": [
        "The fields remain the same as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEr1i-lz7-H0"
      },
      "outputs": [],
      "source": [
        "# JA: https://torchtext.readthedocs.io/en/latest/data.html#fields\n",
        "# The tokenizer is set as the function defined above that returns a list that the spaCy tokenizer\n",
        "# produces.\n",
        "SRC = Field(tokenize = tokenize_de, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMj7s2rI7-H1"
      },
      "source": [
        "Load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHYd_Q0Y7-H1"
      },
      "outputs": [],
      "source": [
        "# JA: From https://torchtext.readthedocs.io/en/latest/datasets.html#multi30k\n",
        "# Create dataset objects for splits of the Multi30k dataset.\n",
        "\n",
        "# Parameters:\t\n",
        "# exts – A tuple containing the extension to path for each language.\n",
        "# fields – A tuple containing the fields that will be used for data in each language.\n",
        "\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
        "                                                    fields = (SRC, TRG))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEPw-QYi7-H2"
      },
      "source": [
        "Build the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzUKL4Un7-H2"
      },
      "outputs": [],
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvHLzycP7-H2"
      },
      "source": [
        "Define the device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwBcygQG7-H2"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYjBKGOI7-H2"
      },
      "source": [
        "Create the iterators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbw1YPY07-H2"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FQT5b1N7-H3"
      },
      "source": [
        "## Building the Seq2Seq Model\n",
        "\n",
        "### Encoder\n",
        "\n",
        "First, we'll build the encoder. Similar to the previous model, we only use a single layer GRU, however we now use a *bidirectional RNN*. With a bidirectional RNN, we have two RNNs in each layer. A *forward RNN* going over the embedded sentence from left to right (shown below in green), and a *backward RNN* going over the embedded sentence from right to left (teal). All we need to do in code is set `bidirectional = True` and then pass the embedded sentence to the RNN as before. \n",
        "\n",
        "![](https://github.com/zaiisao/pytorch-seq2seq/blob/master/assets/seq2seq8.png?raw=1)\n",
        "\n",
        "We now have:\n",
        "\n",
        "$$\\begin{align*}\n",
        "h_t^\\rightarrow &= \\text{EncoderGRU}^\\rightarrow(e(x_t^\\rightarrow),h_{t-1}^\\rightarrow)\\\\\n",
        "h_t^\\leftarrow &= \\text{EncoderGRU}^\\leftarrow(e(x_t^\\leftarrow),h_{t-1}^\\leftarrow)\n",
        "\\end{align*}$$\n",
        "\n",
        "Where $x_0^\\rightarrow = \\text{<sos>}, x_1^\\rightarrow = \\text{guten}$ and $x_0^\\leftarrow = \\text{<eos>}, x_1^\\leftarrow = \\text{morgen}$.\n",
        "\n",
        "As before, we only pass an input (`embedded`) to the RNN, which tells PyTorch to initialize both the forward and backward initial hidden states ($h_0^\\rightarrow$ and $h_0^\\leftarrow$, respectively) to a tensor of all zeros. We'll also get two context vectors, one from the forward RNN after it has seen the final word in the sentence, $z^\\rightarrow=h_T^\\rightarrow$, and one from the backward RNN after it has seen the first word in the sentence, $z^\\leftarrow=h_T^\\leftarrow$.\n",
        "\n",
        "The RNN returns `outputs` and `hidden`. \n",
        "\n",
        "`outputs` is of size **[src len, batch size, hid dim * num directions]** where the first `hid_dim` elements in the third axis are the hidden states from the top layer forward RNN, and the last `hid_dim` elements are hidden states from the top layer backward RNN. We can think of the third axis as being the forward and backward hidden states concatenated together other, i.e. $h_1 = [h_1^\\rightarrow; h_{T}^\\leftarrow]$, $h_2 = [h_2^\\rightarrow; h_{T-1}^\\leftarrow]$ and we can denote all encoder hidden states (forward and backwards concatenated together) as $H=\\{ h_1, h_2, ..., h_T\\}$.\n",
        "\n",
        "`hidden` is of size **[n layers * num directions, batch size, hid dim]**, where **[-2, :, :]** gives the top layer forward RNN hidden state after the final time-step (i.e. after it has seen the last word in the sentence) and **[-1, :, :]** gives the top layer backward RNN hidden state after the final time-step (i.e. after it has seen the first word in the sentence).\n",
        "\n",
        "As the decoder is not bidirectional, it only needs a single context vector, $z$, to use as its initial hidden state, $s_0$, and we currently have two, a forward and a backward one ($z^\\rightarrow=h_T^\\rightarrow$ and $z^\\leftarrow=h_T^\\leftarrow$, respectively). We solve this by concatenating the two context vectors together, passing them through a linear layer, $g$, and applying the $\\tanh$ activation function. \n",
        "\n",
        "$$z=\\tanh(g(h_T^\\rightarrow, h_T^\\leftarrow)) = \\tanh(g(z^\\rightarrow, z^\\leftarrow)) = s_0$$\n",
        "\n",
        "**Note**: this is actually a deviation from the paper. Instead, they feed only the first backward RNN hidden state through a linear layer to get the context vector/decoder initial hidden state. This doesn't seem to make sense to me, so we have changed it.\n",
        "\n",
        "As we want our model to look back over the whole of the source sentence we return `outputs`, the stacked forward and backward hidden states for every token in the source sentence. We also return `hidden`, which acts as our initial hidden state in the decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2__W7FvV7-H3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "5af0fd0d-c853-4e8e-8074-2616f59e4da7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-860e90d61254>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# INPUT_DIM = len(SRC.vocab)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# OUTPUT_DIM = len(TRG.vocab)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# ENC_EMB_DIM = 256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# ENC_HID_DIM = 512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ],
      "source": [
        "class Encoder(nn.Module):\n",
        "    # INPUT_DIM = len(SRC.vocab)\n",
        "    # OUTPUT_DIM = len(TRG.vocab)\n",
        "    # ENC_EMB_DIM = 256\n",
        "    # ENC_HID_DIM = 512\n",
        "    # DEC_HID_DIM = 512\n",
        "    # ENC_DROPOUT = 0.5\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        # JA: From https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
        "        # A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
        "        # This module is often used to store word embeddings and retrieve them using indices. The\n",
        "        # input to the module is a list of indices, and the output is the corresponding word\n",
        "        # embeddings.\n",
        "        # The input dim is needed for the embedding layer to know how the dictionary embedding\n",
        "        # size should be. The embedding dimension is used to describe the amount of channels each\n",
        "        # representation would consist of.\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim) #     nn.Embedding(INPUT_DIM, ENC_EMB_DIM)\n",
        "                                                          # ->  nn.Embedding(len(SRC.vocab), 256)\n",
        "        # torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None,\n",
        "        # norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None, _freeze=False,\n",
        "        # device=None, dtype=None)\n",
        "\n",
        "        # JA: From https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
        "        # Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n",
        "        #\n",
        "        # input_size – The number of expected features in the input x\n",
        "        # hidden_size – The number of features in the hidden state h\n",
        "        # bidirectional – If True, becomes a bidirectional GRU. Default: False\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "        \n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        # JA: When the src goes into the embedding layer, a unique embedding that consists of\n",
        "        # representations for each word is generated. Dropout is used here to prevent overfitting.\n",
        "        # By setting certain values to 0, the encoder is forced to learn more robust representations\n",
        "        # that are less sensitive to specific input values.\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        \n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        # JA: From GRU page:\n",
        "        # outputs shape is (sequence_length, batch, 2*H_out)\n",
        "        # hidden shape is (2*num_layers, batch, H_out)\n",
        "                \n",
        "        #outputs = [src len, batch size, hid dim * num directions]\n",
        "        #hidden = [n layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        #outputs are always from the last layer\n",
        "        \n",
        "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
        "        \n",
        "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
        "        #  encoder RNNs fed through a linear layer\n",
        "\n",
        "        # JA: Here, hidden[-2,:,:] and hidden[-1,:,:] are the second to last and last hidden states,\n",
        "        # respectively.\n",
        "        # The two hidden tensors are concatenated on dim=1 to result in a new shape of\n",
        "        # [batch size, src len * 2]. This is then passed into a fully connected layer to reduce the\n",
        "        # length, resulting in a new shape of [batch size, dec_hid_dim]. With the configuration in\n",
        "        # this notebook, this is also 512, same as enc hid dim. However, because the last two hidden\n",
        "        # layers are concatenated together, this results in something of length 1024. When this\n",
        "        # passes through the FC layer then the resulting tensor shape also has length 512.\n",
        "        # Tanh ultimately caps the value to (-1, 1).\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        #outputs = [src len, batch size, enc hid dim * 2]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        \n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IPtVUxT7-H3"
      },
      "source": [
        "### Attention\n",
        "\n",
        "Next up is the attention layer. This will take in the previous hidden state of the decoder, $s_{t-1}$, and all of the stacked forward and backward hidden states from the encoder, $H$. The layer will output an attention vector, $a_t$, that is the length of the source sentence, each element is between 0 and 1 and the entire vector sums to 1.\n",
        "\n",
        "Intuitively, this layer takes what we have decoded so far, $s_{t-1}$, and all of what we have encoded, $H$, to produce a vector, $a_t$, that represents which words in the source sentence we should pay the most attention to in order to correctly predict the next word to decode, $\\hat{y}_{t+1}$. \n",
        "\n",
        "First, we calculate the *energy* between the previous decoder hidden state and the encoder hidden states. As our encoder hidden states are a sequence of $T$ tensors, and our previous decoder hidden state is a single tensor, the first thing we do is `repeat` the previous decoder hidden state $T$ times. We then calculate the energy, $E_t$, between them by concatenating them together and passing them through a linear layer (`attn`) and a $\\tanh$ activation function. \n",
        "\n",
        "$$E_t = \\tanh(\\text{attn}(s_{t-1}, H))$$ \n",
        "\n",
        "This can be thought of as calculating how well each encoder hidden state \"matches\" the previous decoder hidden state.\n",
        "\n",
        "We currently have a **[dec hid dim, src len]** tensor for each example in the batch. We want this to be **[src len]** for each example in the batch as the attention should be over the length of the source sentence. This is achieved by multiplying the `energy` by a **[1, dec hid dim]** tensor, $v$.\n",
        "\n",
        "$$\\hat{a}_t = v E_t$$\n",
        "\n",
        "We can think of $v$ as the weights for a weighted sum of the energy across all encoder hidden states. These weights tell us how much we should attend to each token in the source sequence. The parameters of $v$ are initialized randomly, but learned with the rest of the model via backpropagation. Note how $v$ is not dependent on time, and the same $v$ is used for each time-step of the decoding. We implement $v$ as a linear layer without a bias.\n",
        "\n",
        "Finally, we ensure the attention vector fits the constraints of having all elements between 0 and 1 and the vector summing to 1 by passing it through a $\\text{softmax}$ layer.\n",
        "\n",
        "$$a_t = \\text{softmax}(\\hat{a_t})$$\n",
        "\n",
        "This gives us the attention over the source sentence!\n",
        "\n",
        "Graphically, this looks something like below. This is for calculating the very first attention vector, where $s_{t-1} = s_0 = z$. The green/teal blocks represent the hidden states from both the forward and backward RNNs, and the attention computation is all done within the pink block.\n",
        "\n",
        "![](https://github.com/zaiisao/pytorch-seq2seq/blob/master/assets/seq2seq9.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rf1HfaGS7-H4"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    # INPUT_DIM = len(SRC.vocab)\n",
        "    # OUTPUT_DIM = len(TRG.vocab)\n",
        "    # ENC_EMB_DIM = 256\n",
        "    # DEC_EMB_DIM = 256\n",
        "    # ENC_HID_DIM = 512\n",
        "    # DEC_HID_DIM = 512\n",
        "    # ENC_DROPOUT = 0.5\n",
        "    # DEC_DROPOUT = 0.5\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        \n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        #repeat decoder hidden state src_len times\n",
        "\n",
        "        # JA: The dimensions of hidden and encoder_outputs must match prior to concatenation.\n",
        "        # Specifically, hidden has shape [batch size, dec_hid_dim], while encoder_outputs has\n",
        "        # shape [src_len, batch_size, enc_hid_dim * 2]. By expanding the second dimension of\n",
        "        # hidden and repeating it src_len times, the resulting tensor has shape\n",
        "        # [batch_size, src_len, dec_hid_dim], which can be concatenated with encoder_outputs,\n",
        "        # resulting in a tensor of shape [batch_size, src_len, enc_hid_dim * 2 + dec_hid_dim].\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #hidden = [batch size, src len, dec hid dim]\n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "        \n",
        "        # JA: The two tensors are concatenated on dim 2, leading to a shape of\n",
        "        # [batch_size, src_len, dec_hid_dim + enc_hid_dim*2]\n",
        "        # -> [batch_size, src_len, 512 + 512*2 = 1536]\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
        "        \n",
        "        #energy = [batch size, src len, dec hid dim]\n",
        "\n",
        "        # JA: What is self.v? Copying from the original text above this cell,\n",
        "        # We can think of  𝑣  as the weights for a weighted sum of the energy across all\n",
        "        # encoder hidden states. These weights tell us how much we should attend to each token\n",
        "        # in the source sequence. The parameters of  𝑣  are initialized randomly, but learned\n",
        "        # with the rest of the model via backpropagation. Note how  𝑣  is not dependent on\n",
        "        # time, and the same  𝑣  is used for each time-step of the decoding. We implement  𝑣 as\n",
        "        # a linear layer without a bias.\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        \n",
        "        #attention= [batch size, src len]\n",
        "        \n",
        "        return F.softmax(attention, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH134AY07-H4"
      },
      "source": [
        "### Decoder\n",
        "\n",
        "Next up is the decoder. \n",
        "\n",
        "The decoder contains the attention layer, `attention`, which takes the previous hidden state, $s_{t-1}$, all of the encoder hidden states, $H$, and returns the attention vector, $a_t$.\n",
        "\n",
        "We then use this attention vector to create a weighted source vector, $w_t$, denoted by `weighted`, which is a weighted sum of the encoder hidden states, $H$, using $a_t$ as the weights.\n",
        "\n",
        "$$w_t = a_t H$$\n",
        "\n",
        "The embedded input word, $d(y_t)$, the weighted source vector, $w_t$, and the previous decoder hidden state, $s_{t-1}$, are then all passed into the decoder RNN, with $d(y_t)$ and $w_t$ being concatenated together.\n",
        "\n",
        "$$s_t = \\text{DecoderGRU}(d(y_t), w_t, s_{t-1})$$\n",
        "\n",
        "We then pass $d(y_t)$, $w_t$ and $s_t$ through the linear layer, $f$, to make a prediction of the next word in the target sentence, $\\hat{y}_{t+1}$. This is done by concatenating them all together.\n",
        "\n",
        "$$\\hat{y}_{t+1} = f(d(y_t), w_t, s_t)$$\n",
        "\n",
        "The image below shows decoding the first word in an example translation.\n",
        "\n",
        "![](https://github.com/zaiisao/pytorch-seq2seq/blob/master/assets/seq2seq10.png?raw=1)\n",
        "\n",
        "The green/teal blocks show the forward/backward encoder RNNs which output $H$, the red block shows the context vector, $z = h_T = \\tanh(g(h^\\rightarrow_T,h^\\leftarrow_T)) = \\tanh(g(z^\\rightarrow, z^\\leftarrow)) = s_0$, the blue block shows the decoder RNN which outputs $s_t$, the purple block shows the linear layer, $f$, which outputs $\\hat{y}_{t+1}$ and the orange block shows the calculation of the weighted sum over $H$ by $a_t$ and outputs $w_t$. Not shown is the calculation of $a_t$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fad8S3ON7-H4"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    # OUTPUT_DIM = len(TRG.vocab)\n",
        "    # DEC_EMB_DIM = 256\n",
        "    # ENC_HID_DIM = 512\n",
        "    # DEC_HID_DIM = 512\n",
        "    # DEC_DROPOUT = 0.5\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        # JA: The attention module is created outside, passed into the decoder, and used within.\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        # JA: nn.GRU(input_size, hidden_size) -> nn.GRU((512*2) + 256 = 1280, 512)\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        \n",
        "        # JA: nn.Linear(input_dim, output_dim) -> nn.Linear(\n",
        "                                                #         (512*2) + 512 + 256 = 1792,\n",
        "                                                #         len(TRG.vocab)\n",
        "                                                # )\n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "             \n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs)\n",
        "                \n",
        "        #a = [batch size, src len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        \n",
        "        #a = [batch size, 1, src len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "        \n",
        "        # JA: What is torch.bmm? From https://pytorch.org/docs/stable/generated/torch.bmm.html\n",
        "        # Performs a batch matrix-matrix product of matrices stored in input and mat2.\n",
        "        # input and mat2 must be 3-D tensors each containing the same number of matrices.\n",
        "        #\n",
        "        # input (Tensor) – the first batch of matrices to be multiplied\n",
        "        # mat2 (Tensor) – the second batch of matrices to be multiplied\n",
        "        #\n",
        "        # The decoder contains the attention layer, attention, which takes the previous\n",
        "        # hidden state,  𝑠𝑡−1 , all of the encoder hidden states,  𝐻 , and returns the\n",
        "        # attention vector,  𝑎𝑡 .\n",
        "        #\n",
        "        # We then use this attention vector to create a weighted source vector,  𝑤𝑡 ,\n",
        "        # denoted by weighted, which is a weighted sum of the encoder hidden states, 𝐻,\n",
        "        # using  𝑎𝑡  as the weights.\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        \n",
        "        #weighted = [batch size, 1, enc hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        \n",
        "        #weighted = [1, batch size, enc hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        \n",
        "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        #output = [seq len, batch size, dec hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
        "        \n",
        "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output = [1, batch size, dec hid dim]\n",
        "        #hidden = [1, batch size, dec hid dim]\n",
        "        #this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden.squeeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJokrLln7-H5"
      },
      "source": [
        "### Seq2Seq\n",
        "\n",
        "This is the first model where we don't have to have the encoder RNN and decoder RNN have the same hidden dimensions, however the encoder has to be bidirectional. This requirement can be removed by changing all occurences of `enc_dim * 2` to `enc_dim * 2 if encoder_is_bidirectional else enc_dim`. \n",
        "\n",
        "This seq2seq encapsulator is similar to the last two. The only difference is that the `encoder` returns both the final hidden state (which is the final hidden state from both the forward and backward encoder RNNs passed through a linear layer) to be used as the initial hidden state for the decoder, as well as every hidden state (which are the forward and backward hidden states stacked on top of each other). We also need to ensure that `hidden` and `encoder_outputs` are passed to the decoder. \n",
        "\n",
        "Briefly going over all of the steps:\n",
        "- the `outputs` tensor is created to hold all predictions, $\\hat{Y}$\n",
        "- the source sequence, $X$, is fed into the encoder to receive $z$ and $H$\n",
        "- the initial decoder hidden state is set to be the `context` vector, $s_0 = z = h_T$\n",
        "- we use a batch of `<sos>` tokens as the first `input`, $y_1$\n",
        "- we then decode within a loop:\n",
        "  - inserting the input token $y_t$, previous hidden state, $s_{t-1}$, and all encoder outputs, $H$, into the decoder\n",
        "  - receiving a prediction, $\\hat{y}_{t+1}$, and a new hidden state, $s_t$\n",
        "  - we then decide if we are going to teacher force or not, setting the next input as appropriate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sb31mpfh7-H5"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "\n",
        "        # JA: Verify src, trg, teacher_forcing_ratio values:\n",
        "        # print(f\"src ({src.shape}): {src}\")\n",
        "        # print(f\"trg: ({trg.shape}): {trg}\")\n",
        "        # print(f\"teacher_forcing_ratio: {teacher_forcing_ratio}\")\n",
        "        #\n",
        "        # Resulting output:\n",
        "        # src (torch.Size([23, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
        "        #         [   8,   54,    5,  ...,    8,    5,    5],\n",
        "        #         [  16, 1551,  717,  ...,   36,   13,   13],\n",
        "        #         ...,\n",
        "        #         [   1,    1,    1,  ...,    1,    1,    1],\n",
        "        #         [   1,    1,    1,  ...,    1,    1,    1],\n",
        "        #         [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
        "        # trg: (torch.Size([21, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
        "        #         [  14,   19,    4,  ...,    4,    4,    9],\n",
        "        #         [  13, 1693,  192,  ...,   38,    9,   22],\n",
        "        #         ...,\n",
        "        #         [   1,    1,    1,  ...,    1,    1,    1],\n",
        "        #         [   1,    1,    1,  ...,    1,    1,    1],\n",
        "        #         [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
        "        # teacher_forcing_ratio: 0.5\n",
        "\n",
        "        # JA: WHY is src len and trg len different? (See tensor shapes above)\n",
        "        # The reason for this is that the sentences themselves are different. The src and trg\n",
        "        # tensors are tokenized versions of the language pair sentences, and these would obviously\n",
        "        # have different lengths.\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "        \n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        # JA: From declaration of Seq2Seq: OUTPUT_DIM = len(TRG.vocab)\n",
        "        # In this context target vocab size is synonymous with decoder output dimension.\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden state and all encoder hidden states\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRdyyvd_7-H5"
      },
      "source": [
        "## Training the Seq2Seq Model\n",
        "\n",
        "The rest of this tutorial is very similar to the previous one.\n",
        "\n",
        "We initialise our parameters, encoder, decoder and seq2seq model (placing it on the GPU if we have one). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egddYpCR7-H5"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P_sV4v37-H5"
      },
      "source": [
        "We use a simplified version of the weight initialization scheme used in the paper. Here, we will initialize all biases to zero and all weights from $\\mathcal{N}(0, 0.01)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-E9Q0sI7-H6",
        "outputId": "646a5905-6277-4e31-fe2c-8aeca4d74a24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(7853, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(5893, 256)\n",
              "    (rnn): GRU(1280, 512)\n",
              "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuothqDy7-H6"
      },
      "source": [
        "Calculate the number of parameters. We get an increase of almost 50% in the amount of parameters from the last model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFUQUg397-H6",
        "outputId": "2cb700a0-092c-4f43-988c-68daf30a8ec4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 20,518,405 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iidK8Qux7-H6"
      },
      "source": [
        "We create an optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMNSnK6n7-H6"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhzz1gaY7-H6"
      },
      "source": [
        "We initialize the loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Sz6n2Vr7-H6"
      },
      "outputs": [],
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkZOn6yg7-H7"
      },
      "source": [
        "We then create the training loop..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jTe9FyB7-H7"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph7M8qfU7-H7"
      },
      "source": [
        "...and the evaluation loop, remembering to set the model to `eval` mode and turn off teaching forcing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiB5jkJa7-H7"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R768oPT7-H7"
      },
      "source": [
        "Finally, define a timing function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qpY9scy7-H7"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py3VyMID7-H7"
      },
      "source": [
        "Then, we train our model, saving the parameters that give us the best validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7p-gVOV7-H8",
        "outputId": "04cbda9a-47f4-49d1-82ef-cce553ef2d57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "        [ 15,   5,   5,  ...,  18,   5,   8],\n",
            "        [884,  25,  70,  ...,  45, 932,  36],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([35, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  7,   4,  53,  ...,  16,   4,   4],\n",
            "        [106,  33,  34,  ...,  50, 170,  38],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   30,  182,  ..., 3342,    8,    5],\n",
            "        [1188,   57,   56,  ..., 5907,   16,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   30,  107,  ..., 1487,    4,    4],\n",
            "        [   9,   17,  340,  ..., 1332,   14,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    8,  ...,    5,    8,    5],\n",
            "        [4872,   16,   16,  ...,  738,   56,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,   4,   4],\n",
            "        [602,  14,  14,  ..., 237,  38,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,  18,  15,  ...,   5,   5,   5],\n",
            "        [ 16, 174,  13,  ...,  13,  13,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  16,   7,  ...,   4,   4,   4],\n",
            "        [ 14, 233,   9,  ...,   9,   9,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,  15,   8,  ..., 105,  76,   8],\n",
            "        [121,  13,  67,  ..., 902,  41,  16],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   7,   4,  ..., 110,  19,  14],\n",
            "        [112,   9,  64,  ...,  30, 359,   6],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([35, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 43,   5,   5,  ...,   8,   5,  16],\n",
            "        [  0,  13,  13,  ...,  16, 116,  11],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([35, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 48,   4,   4,  ...,   4,   4,  14],\n",
            "        [699,   9,   9,  ...,  14, 485,   6],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    8,  ...,   43,    5,    5],\n",
            "        [  26,   13,   36,  ...,  371, 1049,  164],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,   48,    4,    4],\n",
            "        [  34,    9,   38,  ...,  360, 1823,  153],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   8,  ...,  54,   5,  39],\n",
            "        [ 49, 632,  67,  ...,  74, 863, 116],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   46,   64,  ...,   19,   61,    7],\n",
            "        [ 348, 1012,  169,  ...,  607,   11,  154],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,  18,  ...,   5,   5,   5],\n",
            "        [ 13, 329,  30,  ...,  66,  25, 717],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,  16,  ...,   4,   4,  46],\n",
            "        [  9,  59,  30,  ...,  53,  33, 192],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   5],\n",
            "        [  1,   1,   1,  ...,   1,   1,   3],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([24, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   5,   8,  ...,   8,  43,   5],\n",
            "        [234, 299,  36,  ...,  36,   0,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [122,   4,   4,  ...,   4,  48,   4],\n",
            "        [ 14, 357,  38,  ...,  38, 168,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,  216,    8,   18],\n",
            "        [  25, 1459,  431,  ...,   41,   16,   73],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ..., 251,  14,  16],\n",
            "        [ 33, 353,  64,  ...,  19,   6,  19],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,   18,    8,    8],\n",
            "        [  70,    0,   13,  ..., 1459,  315,   16],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,  16,  21,   4],\n",
            "        [ 53, 602,   9,  ..., 353, 106,  14],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,   5,   8,  ...,   8,  18,   8],\n",
            "        [ 26, 371,   0,  ...,  16,  30,  16],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([37, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,   4,  ...,   4,  16,   4],\n",
            "        [ 24, 123,  26,  ...,  14,  30,  14],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,    8,  ...,    5,    5,    8],\n",
            "        [ 274,   13, 5901,  ...,   32, 1004,   16],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    4,    4,    4],\n",
            "        [  14,    9,  998,  ...,   35, 4332,   14],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   5,  76,  ...,   5,   8,   8],\n",
            "        [ 36, 171,  41,  ...,  25,  36,  16],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   3,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4,  4,  4,  ...,  4,  4,  4],\n",
            "        [38, 61, 38,  ..., 33, 38, 14],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ..., 1586,    5,    5],\n",
            "        [ 272,   13,   70,  ...,   13,   70, 2352],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 21,   4,  53,  ...,   9,   4, 644],\n",
            "        [145,   9,  34,  ...,   6,  53, 674],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([37, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,    5,  ...,  325,    8,  452],\n",
            "        [  16, 2648,   13,  ...,  303,   16,    7],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,   21,    4,  209],\n",
            "        [  14, 2054,    9,  ..., 1196,   14,  174],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  99,  661,    5,  ...,    8,    5,    5],\n",
            "        [1388,   32,   26,  ...,   36,   13,  150],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 313,   86,    4,  ...,    4,    4,    4],\n",
            "        [2579,   35,   34,  ...,   38,    9,   25],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,  15,  ...,   5, 191,   5],\n",
            "        [ 32,  13, 538,  ...,  13,  41,  70],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    7,  ...,   46,  202, 1145],\n",
            "        [  35,    9,  648,  ...,    9,   19,  324],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([25, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,   5,   5,  ...,  70,   5,   5],\n",
            "        [ 30,  26, 241,  ...,  26,  13,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,  29,   1],\n",
            "        [  1,   1,   1,  ...,   1,   4,   1],\n",
            "        [  1,   1,   1,  ...,   1,   3,   1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,   4,  ...,  24,   4,   4],\n",
            "        [ 30,  34, 323,  ...,  34,   9,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,    5, 1607,  ...,   18,    5,    5],\n",
            "        [  30,   13,   73,  ...,   30,  551,  716],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4, 762,  ...,  16,   4,   4],\n",
            "        [ 30,   9,  19,  ...,  30,  24, 192],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,    8,    5,    5],\n",
            "        [  25, 1608, 2168,  ...,   67,   66,    0],\n",
            "        ...,\n",
            "        [   1,   48,    1,  ...,    1,    1,    1],\n",
            "        [   1,    4,    1,  ...,    1,    1,    1],\n",
            "        [   1,    3,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    4,    4, 4085],\n",
            "        [  33,  224,  168,  ...,   64,   53,   25],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 8,  8,  8,  ...,  5,  8,  5],\n",
            "        [16, 36, 16,  ..., 13, 16, 13],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4,  4,  4,  ...,  4,  4,  4],\n",
            "        [14, 38, 14,  ...,  9, 14,  9],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,    5,  ...,   18,    8,   39],\n",
            "        [  16,   13,  177,  ...,  890, 4797,  148],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ..., 417,   4,   7],\n",
            "        [ 14,   9,  24,  ...,  26, 120, 342],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([25, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  15,    5,    5,  ...,    5, 1904,    8],\n",
            "        [ 269,   13, 1335,  ...,  959,   41,   67],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   7,    4,    4,  ...,  781, 1146,    4],\n",
            "        [ 105,    9, 1371,  ...,    8,   19,   64],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,   30,  ...,  105,   18,    5],\n",
            "        [ 308, 1225,    7,  ...,   45,   30,  114],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  9,   4,  30,  ..., 110,  16, 176],\n",
            "        [ 10, 855,   6,  ...,  50,   9,  10],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([25, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   18,  216,  ...,   18,    5,   18],\n",
            "        [ 369, 6822,  168,  ...,   45,  329,  174],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([24, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 21,  16, 251,  ...,  16,   4,  16],\n",
            "        [587, 104,  59,  ...,  50, 404, 115],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   3,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [416,   5,  12,  ...,  18,   5,   5],\n",
            "        [ 48,  13,  24,  ...,  30, 232, 130],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [176,   4,  19,  ...,  16,   4,  21],\n",
            "        [ 10,   9,  32,  ...,  50,  25, 115],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,   5,  ...,   5,   5,   5],\n",
            "        [ 70,  16,  13,  ..., 986, 371,  26],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   3,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,   4,  34],\n",
            "        [ 53,  14,   9,  ..., 480, 123,  22],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ..., 103,   1,   1],\n",
            "        [  1,   1,   1,  ...,   5,   1,   1],\n",
            "        [  1,   1,   1,  ...,   3,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([25, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,  18,   5,  ...,   5,   5,   5],\n",
            "        [232,  45,  70,  ...,  70,  13,  32],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([23, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4, 16,  4,  ...,  4,  4,  4],\n",
            "        [ 9, 50, 70,  ..., 53,  9, 35],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [7406,    8,    5,  ...,    5,   18,    5],\n",
            "        [ 151,   67,   13,  ...,  177,   30, 1783],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([36, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 39,   4,   4,  ...,   4,  16,  21],\n",
            "        [428,  64,   9,  ...,  24,  30, 324],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([34, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 5, 18,  5,  ...,  5,  5,  5],\n",
            "        [49, 80, 13,  ..., 13, 32, 13],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "trg: (torch.Size([40, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4, 16,  4,  ...,  4,  4,  4],\n",
            "        [55, 24,  9,  ...,  9, 35,  9],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [18,  8,  5,  ...,  5,  5, 43],\n",
            "        [30, 16, 26,  ..., 70, 26, 26],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,   4,  ...,  53,   4,  48],\n",
            "        [ 30,  14,  34,  ..., 174,  34,  24],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([38, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   18,    8,  ...,    5,    5,    5],\n",
            "        [   0,   30,   67,  ..., 2785,   13,   25],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([36, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   16,  176,  ...,    4,    4,   33],\n",
            "        [1377,   30,   10,  ...,  591,    9,   45],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,   39,   18,  ...,    5,    5,    5],\n",
            "        [  54, 2404, 2195,  ...,   32,   26,   26],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  16,    7,   16,  ...,    4,    4,    4],\n",
            "        [  19, 1949,   26,  ...,   35,   34,   24],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([34, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,  43,   5,  ...,  73,   5,   5],\n",
            "        [150,  41,  66,  ...,   9,  13, 171],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4, 48,  4,  ..., 19,  4,  4],\n",
            "        [25, 19, 70,  ..., 79,  9, 61],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([35, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  43,    8,    5,  ...,    5,   30,    5],\n",
            "        [ 315,   67, 5820,  ...,   13,   52,   66],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 48,   4,   4,  ...,   4,  30,   4],\n",
            "        [106,  64,   0,  ...,   9,  17,  53],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,    5,    5,    5],\n",
            "        [ 884, 1188,   13,  ...,  516,   96,  518],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 21,   4,   9,  ...,   4,  46,   4],\n",
            "        [106, 163,  56,  ..., 491,  24,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 8,  8,  5,  ..., 18,  5, 15],\n",
            "        [36, 16, 13,  ..., 30, 70,  0],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4,  4,  4,  ..., 16,  4,  7],\n",
            "        [38, 14,  9,  ..., 30, 24, 35],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    8,  ...,  221,    5,    8],\n",
            "        [  26, 1382,   16,  ...,   30,   25,   16],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,  74,  33,   4],\n",
            "        [ 34, 263,  14,  ...,  30,  13, 120],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    8,  ...,    8,   18,   18],\n",
            "        [  13, 1189,   16,  ...,   16,   30,    0],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([36, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    4,   16,   16],\n",
            "        [   9,   38,   14,  ...,   14,   30, 1736],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,   5,   5,  ..., 221,   0,   8],\n",
            "        [ 45,  66,  13,  ...,  41,  15,  67],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  16,    4,    4,  ...,   74,    4,    4],\n",
            "        [  50,   53,    9,  ...,   19, 3310,   64],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,    8,    8,  ...,   18,    5,  105],\n",
            "        [ 390,    0,  364,  ...,   45, 1459,   45],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,   34,    1,    1],\n",
            "        [   1,    1,    1,  ...,    4,    1,    1],\n",
            "        [   1,    1,    1,  ...,    3,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16, 209,   4,  ...,  16,   4, 110],\n",
            "        [145,  10, 496,  ...,  50, 583,  50],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ..., 768,   5,   1],\n",
            "        [  1,   1,   1,  ...,   5,   3,   1],\n",
            "        [  1,   1,   1,  ...,   3,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([24, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   5,   5,  ...,   5,  43,  17],\n",
            "        [ 36, 717,  13,  ..., 384,  41,  65],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,  28,   1,   1],\n",
            "        [  1,   1,   1,  ...,   4,   1,   1],\n",
            "        [  1,   1,   1,  ...,   3,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,  106,   48,    7],\n",
            "        [  38, 1835,    9,  ...,    9,   19,   63],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([45, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,   5,  ...,   5,  15,   5],\n",
            "        [ 70, 315,  96,  ...,  32, 308,  70],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([42, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4, 106,   4,  ...,   4,   7,  70],\n",
            "        [ 53, 642,  24,  ...,  35, 868,  34],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,   18,    7,  ...,    5,    8,    5],\n",
            "        [  36,   30,   15,  ...,   13, 2417, 2545],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([35, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   16,   19,  ...,    4,    4,    4],\n",
            "        [  38,   30,  164,  ...,    9,   39, 5073],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 15,   5,   5,  ...,   5,   5,   5],\n",
            "        [  0,  70,  26,  ...,  13,  49, 503],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   7,    7,    4,  ...,    4,    4,    4],\n",
            "        [5674,  153,   34,  ...,    9,   55, 1012],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   18,   15,  ...,    5,    5,   18],\n",
            "        [  26,  103,   26,  ...,   66,   13, 1347],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  16,   7,  ...,  53,   4,  16],\n",
            "        [ 34,  24,  34,  ...,  33,   9, 639],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,   18,  ...,    5,    5,    5],\n",
            "        [5291,   25,   73,  ..., 1675,   13,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,  583,    1],\n",
            "        [   1,    1,    1,  ...,    1,    4,    1],\n",
            "        [   1,    1,    1,  ...,    1,    3,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,   16,  ...,   21,    4,    4],\n",
            "        [2037,   33,   19,  ...,  145,    9,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,  723,    1],\n",
            "        [   1,    1,    1,  ...,    1,    5,    1],\n",
            "        [   1,    1,    1,  ...,    1,    3,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([34, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 103,    8, 1071,  ...,    5,    5,    5],\n",
            "        [  80,   16,   44,  ...,   96,   32, 3718],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  53,    4, 1115,  ...,    4,    4,    4],\n",
            "        [ 127,   14,   12,  ...,   24,   35,  975],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 5,  5,  5,  ...,  5,  5,  5],\n",
            "        [70,  0, 66,  ..., 13, 13, 13],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4,  4, 24,  ...,  4,  4,  4],\n",
            "        [53,  0, 55,  ...,  9,  9,  9],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   5,  18,  ...,   5,   8,   5],\n",
            "        [113,  66,  65,  ...,  13, 330,  66],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 87,   4,  16,  ...,   4,  21,   4],\n",
            "        [ 12,  53,  63,  ...,   9, 387,  24],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,   18,  ...,    8,   43,    8],\n",
            "        [  13,   25,  550,  ..., 1518,   80,   16],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,  16,  ..., 324,  48,   4],\n",
            "        [  9,  33, 224,  ..., 327, 127, 183],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 5,  8, 43,  ...,  5,  5,  5],\n",
            "        [49, 16, 45,  ..., 13, 13, 13],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,   48,  ...,    4,    4,    9],\n",
            "        [  55,   14,   50,  ...,    9,    9, 5759],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   18,    8,  ...,    5, 1904,  191],\n",
            "        [  13, 1002,   16,  ...,   66, 1280,   54],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   16,    4,  ...,    4, 1146,  202],\n",
            "        [   9,  719, 2614,  ...,   24, 1227,   19],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,  18,  ...,   5,  12,   5],\n",
            "        [130,  70, 168,  ...,  96,  14, 388],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([35, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 21,   4,  16,  ...,   4,   8,   4],\n",
            "        [233,  24,  59,  ...,  24,   4,  25],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,  18,   5,  ...,   5,   8,   5],\n",
            "        [ 26,  80,  13,  ..., 613, 920,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   16,    4,  ...,   62,    4,    4],\n",
            "        [  34,   53,    9,  ..., 1596,   38,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   8,  ...,   8,   5,   5],\n",
            "        [130,  13,  16,  ...,  36, 150,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 21,   4,   4,  ...,   4,   4,   4],\n",
            "        [233,   9,  14,  ...,  38,  25,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 26,  18, 191,  ..., 435,   5,   8],\n",
            "        [ 25,  30,  73,  ...,   7,  96,  16],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 24,  16, 837,  ...,   4,  24,   4],\n",
            "        [104,  30,  12,  ..., 188,   9,  14],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,  325,    5,    5],\n",
            "        [  13,   13,   13,  ...,   68, 2225,   70],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4,  4,  4,  ...,  4,  4,  4],\n",
            "        [ 9,  9,  9,  ..., 64,  9, 34],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 43,   5,  30,  ...,   8,   5,   5],\n",
            "        [510,  13, 179,  ..., 174,   0,  25],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 681,    4,   30,  ...,  115,   21,    4],\n",
            "        [ 161,    9,  130,  ...,   14, 3273,   33],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([25, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  65,    8,   39,  ..., 1046,    5,    5],\n",
            "        [  20,  168,   25,  ...,  548,   25,   25],\n",
            "        ...,\n",
            "        [   1,    1,    4,  ...,    1,    1,    1],\n",
            "        [   1,    1,    3,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  24,    4,    7,  ..., 1595,    4,    4],\n",
            "        [  63,   59,   33,  ...,  569,   33,   33],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,   5,  45,  ...,   8,  18,  43],\n",
            "        [858, 177,  52,  ...,  26, 541, 253],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1, 791],\n",
            "        [  1,   1,   1,  ...,   1,   1,   4],\n",
            "        [  1,   1,   1,  ...,   1,   1,   3]], device='cuda:0')\n",
            "trg: (torch.Size([36, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  16,    4,   50,  ...,    4,   16,   48],\n",
            "        [ 747,   24,   36,  ...,   24,  415,   25],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1, 1136],\n",
            "        [   1,    1,    1,  ...,    1,    1,    5],\n",
            "        [   1,    1,    1,  ...,    1,    1,    3]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,   8,  ...,   5,   8,  43],\n",
            "        [ 13,  26,  16,  ...,  13,  16, 121],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,   4,  48],\n",
            "        [168,  24,  14,  ...,   9,  14, 112],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   5,   5,  ...,   5,   8,   5],\n",
            "        [113,  13,  13,  ...,  26,  16,  96],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4,  9,  4,  ...,  4,  4,  4],\n",
            "        [87,  6,  9,  ..., 34, 14, 24],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([24, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   0,   5,  ...,   5,   5,   5],\n",
            "        [274, 279, 130,  ..., 452,  70, 130],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4, 2552,   21,  ...,    4,    4,   21],\n",
            "        [ 122,  254,  233,  ...,  174,   24,  115],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,    8,    5,    5],\n",
            "        [  13,    0,  130,  ..., 5589,   13,   66],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,   21,  ..., 4101,  209,    4],\n",
            "        [   9, 3536,  233,  ...,   14,    4,   53],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  54,    5,    8,  ...,    5,    5,    5],\n",
            "        [   7,   13,   16,  ..., 4704,   13,    0],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  19,    4,  120,  ...,    4,    4,   16],\n",
            "        [   6,    9,  786,  ...,  624,    9, 4976],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([24, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5, 105,  ...,  76,   5, 191],\n",
            "        [ 49,  25, 121,  ...,  41,  13,  30],\n",
            "        ...,\n",
            "        [  3,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([25, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4, 110,  ...,   4,   4, 202],\n",
            "        [ 55,  33, 112,  ...,  38,   9,  30],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   0,    5,    8,  ...,   43,    5,    5],\n",
            "        [1551,   70,  390,  ...,   45,  150,   49],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  0,   4,  21,  ..., 681,  25,   4],\n",
            "        [  0,  53, 145,  ...,  50,   9,  55],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,  492,  ...,    5,    5,    5],\n",
            "        [ 384,   13,   45,  ...,   13,   70, 1095],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 21,   4, 860,  ...,   4,   4,   4],\n",
            "        [106,   9,  50,  ...,   9,  24, 771],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([36, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,    8,    5,    5],\n",
            "        [ 308,   13,  209,  ..., 6602,   49,   25],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,  832,  ..., 1853,    4,   46],\n",
            "        [  64,    9,   10,  ...,   12,   55,   33],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  41,    8,    8,  ...,   43,    8,    8],\n",
            "        [ 163,  113,   16,  ..., 4987,   36,  174],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([38, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 19,   4,   4,  ...,  48,   4,  21],\n",
            "        [  6, 664,  14,  ..., 399,  38, 233],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,   5,  ...,   5,  18,  18],\n",
            "        [ 13,  36,  26,  ..., 572, 390, 121],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   7,  ...,   4,  16,  16],\n",
            "        [  9,  38,  34,  ..., 665, 145, 112],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,    8,  231,  ...,    5,   18,    5],\n",
            "        [ 121,   16, 1524,  ...,   70,   45,  734],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  16,    4, 1524,  ...,    4,   16,    4],\n",
            "        [ 112,   14,    4,  ...,   24,   50,  282],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 5,  8,  5,  ..., 43,  5, 43],\n",
            "        [13, 26, 13,  ..., 65, 13, 30],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,  48,   4,  48],\n",
            "        [  9,  24,   9,  ..., 196,   9,  30],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   3],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 72])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  17,   18,    8,  ...,    5,   18,    5],\n",
            "        [  67,  435,   36,  ...,   25, 3559,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 72])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  7,  16,   4,  ...,   4,  16,   4],\n",
            "        [ 64, 188,  38,  ...,  33,  19,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   8,  15,  ...,   5,   5,  76],\n",
            "        [ 67,  36,  26,  ...,  13,  49, 174],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   7,  ...,   4,   4, 113],\n",
            "        [ 64,  38,  34,  ...,   9,  55, 233],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([41, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   5,   5,  ...,   8,   5,   5],\n",
            "        [174,  13, 782,  ...,  16,  70,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([42, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 21,   4,   4,  ...,   4,   4,   4],\n",
            "        [115,   9, 480,  ...,  14,  53,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,   17,    8,  ...,   18,   18,   18],\n",
            "        [  30, 1423,  113,  ...,  121,   30,   25],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([25, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16, 781,   4,  ...,  16,  16,  16],\n",
            "        [ 30,   0,  38,  ..., 112, 360, 104],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([38, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,   5,   5,  ...,   8, 221,  18],\n",
            "        [515,  25, 909,  ...,  36,  41, 103],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([37, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,   4,  ...,   4,   4,  16],\n",
            "        [ 61,  33, 735,  ...,  38, 154,  24],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   5,  ...,   5,   5,  18],\n",
            "        [452,  13,   0,  ..., 961,  70,  30],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,   4,  16],\n",
            "        [174,   9, 163,  ..., 398,  53,  30],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,    5,    5,  ...,  241,   18,    5],\n",
            "        [ 274, 1332,  551,  ...,    7,  121, 1253],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  16,    4,    4,  ...,  228,   16,    4],\n",
            "        [ 122,   64,  122,  ...,    6,  112, 1067],\n",
            "        ...,\n",
            "        [   5,    1,    1,  ...,    1,    1,    1],\n",
            "        [   3,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 73,   5,   8,  ...,   5,  18,   8],\n",
            "        [ 53, 329,  67,  ...,  13, 103, 113],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([33, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  19,  404,    4,  ...,    4,   16,    4],\n",
            "        [ 150,   26, 4280,  ...,    9,   53,   87],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 43,  18,   0,  ...,   8,   8,  18],\n",
            "        [ 45,  45, 165,  ..., 113, 165,  45],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 48,  16,   4,  ...,   4,   4,  16],\n",
            "        [ 50,  50, 120,  ...,  87, 120,  50],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,    8,    5,  ...,   18,    8,    5],\n",
            "        [ 503, 1591,  269,  ...,  121,   16,   49],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,   4,  ...,  16,   4,   4],\n",
            "        [946, 183, 105,  ..., 112,  14,  55],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   5,   5,  ...,   5,   5, 582],\n",
            "        [103,  26,  66,  ...,  13,  49,  10],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,  55,   4],\n",
            "        [ 70,  34,  70,  ...,   9,  22, 642],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5, 105,  ...,   5, 216,  18],\n",
            "        [ 70, 130,  30,  ...,   0,  41,  45],\n",
            "        ...,\n",
            "        [ 90,   1,   1,  ...,   1,   1,   1],\n",
            "        [  4,   1,   1,  ...,   1,   1,   1],\n",
            "        [  3,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,  233,  110,  ...,    4,  251,   16],\n",
            "        [  24,    9,   30,  ..., 5659,   19,   50],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   8,  ...,   8,   5,   5],\n",
            "        [ 13,  70,  16,  ..., 274,  13, 116],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,   4,   4],\n",
            "        [  9,  24,  14,  ..., 122,   9, 154],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  15,    5,    8,  ...,   73,    5,    5],\n",
            "        [3005,   13,   16,  ...,   52,  299,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  7,   4,   4,  ...,  19,   4,   4],\n",
            "        [ 26,   9,  14,  ...,  17, 357,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([11, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   5,  ...,  26,  65,   5],\n",
            "        [ 13,  13,  13,  ...,  68, 137,  13],\n",
            "        ...,\n",
            "        [588,  91,  14,  ...,   1,   1,   1],\n",
            "        [  4,   4, 714,  ...,   1,   1,   1],\n",
            "        [  3,   3,   3,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([13, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,  34, 196,   4],\n",
            "        [  9,   9,   9,  ..., 169,  17,   9],\n",
            "        ...,\n",
            "        [  3,   3,   3,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "src (torch.Size([13, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  54,   18,    5,  ...,    5,   30,   32],\n",
            "        [3992,   54,  518,  ...,   66,    7, 1964],\n",
            "        ...,\n",
            "        [   4,   34,    4,  ...,    3,    3,    3],\n",
            "        [   3,    3,    3,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([13, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  19,   16,    4,  ...,    4,   30,   35],\n",
            "        [1581,   19,    9,  ...,   53,   22,    6],\n",
            "        ...,\n",
            "        [   5,  142,    5,  ...,    3,    3,    3],\n",
            "        [   3,    3,    3,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "src (torch.Size([13, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    5,  ...,    8,   39,   32],\n",
            "        [ 173,    0, 1427,  ...,   36,   48,   21],\n",
            "        ...,\n",
            "        [   4,    4,    4,  ...,    4,    4,    4],\n",
            "        [   3,    3,    3,  ...,    3,    3,    3],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([16, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   21,    4,  ...,    4,  209,   35],\n",
            "        [  34, 2720, 1103,  ...,   38,   10,    8],\n",
            "        ...,\n",
            "        [   5,    5,    5,  ...,    1,    1,    1],\n",
            "        [   3,    3,    3,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "src (torch.Size([17, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   80,   18,  ...,    5,    8,   18],\n",
            "        [  26,   10,  490,  ...,  502, 6787,   30],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([17, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,  127,    4,  ...,    4,    4,   16],\n",
            "        [  34,   11,  154,  ...,  510, 1909,   30],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    3,    3,    3],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "src (torch.Size([15, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    5,  ...,    5,    5,    5],\n",
            "        [1586,   26,  298,  ...,   96,   49,   26],\n",
            "        ...,\n",
            "        [ 129,  169,   12,  ...,    4,    4,    4],\n",
            "        [   4,    4,    4,  ...,    3,    3,    3],\n",
            "        [   3,    3,    3,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([17, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4, 176,   4,  ...,   4,   4,   4],\n",
            "        [ 36,  10, 216,  ...,  24,  55,  34],\n",
            "        ...,\n",
            "        [126,  77, 576,  ...,   1,   1,   1],\n",
            "        [  5,   5,   5,  ...,   1,   1,   1],\n",
            "        [  3,   3,   3,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "src (torch.Size([17, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,    5,    5,    5],\n",
            "        [  13,   13,   13,  ...,  194,  130,   26],\n",
            "        ...,\n",
            "        [7688,  617,    0,  ...,    4,    4,    3],\n",
            "        [   4,    4,    4,  ...,    3,    3,    1],\n",
            "        [   3,    3,    3,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([21, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,  21,   4],\n",
            "        [  9,   9,   9,  ..., 180, 115,  34],\n",
            "        ...,\n",
            "        [  3,   3,   3,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "src (torch.Size([24, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,   24,  ...,   15,   18,    5],\n",
            "        [  67, 1225,   25,  ...,  452,   65,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    7,   16,    4],\n",
            "        [  64, 2066,  409,  ...,  174,   63,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "src (torch.Size([35, 118])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,    5,  ...,    8,    5,    8],\n",
            "        [  26,   25, 6756,  ...,  582,   66,   16],\n",
            "        ...,\n",
            "        [   4,  220,    1,  ...,    1,    1,    1],\n",
            "        [   3,    4,    1,  ...,    1,    1,    1],\n",
            "        [   1,    3,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 118])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   32,    4,  ...,    4,    4,    4],\n",
            "        [  24, 1991,  161,  ...,  642,   24,   14],\n",
            "        ...,\n",
            "        [   1,    1, 1335,  ...,    1,    1,    1],\n",
            "        [   1,    1,    5,  ...,    1,    1,    1],\n",
            "        [   1,    1,    3,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "Epoch: 09 | Time: 1m 31s\n",
            "\tTrain Loss: 1.617 | Train PPL:   5.037\n",
            "\t Val. Loss: 3.283 |  Val. PPL:  26.662\n",
            "src (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,  54,  ...,   5,  18,   5],\n",
            "        [ 13,  13,   7,  ...,  13, 510, 171],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  9,   4,  19,  ...,   4,  16,   4],\n",
            "        [249,   9,   6,  ...,   9, 161,  61],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([38, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   5,  18,  ...,  18, 148,   8],\n",
            "        [ 67,  13,  41,  ...,  26,  14, 243],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([37, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  21,    4,   16,  ...,   16,  342,    4],\n",
            "        [1196,    9,   19,  ...,   24,   12,   26],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,  18,   8,  ...,  15, 384,   5],\n",
            "        [ 13,  41,  16,  ..., 942,  26,  66],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  16,   4,  ...,   7, 106,   4],\n",
            "        [  9,  19,  14,  ..., 213,  24,  70],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [191,  18,   5,  ...,   8,  43,  43],\n",
            "        [241,  45, 130,  ..., 174,  25, 655],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([25, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [1571,   16,   21,  ...,   21,   48,   48],\n",
            "        [ 228,   50,  115,  ...,  115,  104,  104],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([24, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [18,  5, 43,  ..., 73,  5,  5],\n",
            "        [45, 13, 25,  ...,  9, 25, 70],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "trg: (torch.Size([24, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,  48,  ...,  19,   4,   4],\n",
            "        [ 50,   9, 104,  ..., 189,  33,  53],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  65,   18,    8,  ...,    5,    8,   18],\n",
            "        [  93,   30,   67,  ..., 3240,   16,   45],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 196,   16,    4,  ...,    4,    4,   16],\n",
            "        [  17,   30,  235,  ..., 2962,   14,   50],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    5,  ...,    8,  216,    8],\n",
            "        [  13,   36,   13,  ..., 3109,   30,   67],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4, 251,   4],\n",
            "        [  9,  38,   9,  ..., 606, 602,  64],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   5,  ..., 661,   5,  43],\n",
            "        [ 13, 954,  13,  ...,  32, 177, 103],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,  86,   4,  48],\n",
            "        [  9, 467,   9,  ...,  35,  24,  53],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([36, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,    5,  ...,    5,   15,    5],\n",
            "        [ 274,    0,   13,  ...,  734, 4651,   26],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    7,    7,    4],\n",
            "        [ 122, 1185,    9,  ...,  299,  132,   24],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  45,    8,   15,  ...,    5,   18,    5],\n",
            "        [4957,   16,   26,  ...,   13,   30,    0],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [860,   4,   7,  ...,   4,  16,   4],\n",
            "        [ 14,  14,  34,  ...,   9,  30, 132],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    8,    8,  ...,    5,   30,    5],\n",
            "        [  16,   67,  113,  ...,   32,    9, 1399],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 120,    4,    4,  ...,    4,   30,    4],\n",
            "        [  41,   64,   87,  ...,   35,   73, 1212],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    8,  ...,    5,    5,    5],\n",
            "        [ 116,   67,   36,  ...,  468,   13, 1815],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 74,   4,   4,  ...,   7,   4,   4],\n",
            "        [ 19,  64,  38,  ..., 552,   9,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 15,   8, 298,  ...,   5,   5, 413],\n",
            "        [ 32, 103,  31,  ..., 298,  13,  65],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  7,   4,   4,  ...,   4,   4, 457],\n",
            "        [ 35,  70, 216,  ..., 216,   9,  63],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   18,    5,  ...,   18,  105,    5],\n",
            "        [ 130,  890,   13,  ..., 4011,   30,  550],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  21,   16,    4,  ...,   16,  110,    4],\n",
            "        [ 115,  178,    9,  ..., 3500,   30,  224],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    5,  ...,   18,  105,  216],\n",
            "        [  25,  168,  942,  ...,   73, 4952,   41],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,  16, 110, 251],\n",
            "        [ 33,  59, 213,  ...,  19, 362,  19],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,   26,   17,  ...,    5,    5,    8],\n",
            "        [  16,   16, 1495,  ...,   13,  329,  346],\n",
            "        ...,\n",
            "        [   4,    1,    1,  ...,    1,    1,    1],\n",
            "        [   3,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   24,    7,  ...,    4,    4,    4],\n",
            "        [  14,   14, 2065,  ...,    9,  289,  272],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,  20,  ...,   8,   5,   8],\n",
            "        [114,  36, 670,  ...,  16,  26,  16],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([24, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4,  4, 46,  ...,  4,  4,  4],\n",
            "        [26, 38, 14,  ..., 14, 24, 14],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,    5,   18,  ...,    5,    8,   18],\n",
            "        [  54,   13,   80,  ..., 1359,   16,   41],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([38, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,  16,  ...,   4,  14,  16],\n",
            "        [ 19,   9, 127,  ...,  26,   6,  19],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,  18,  17,  ...,  25,   5,   8],\n",
            "        [ 25,  30,  16,  ...,  62,  13, 230],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  16,   7,  ...,  33,   4, 200],\n",
            "        [ 33,  30, 120,  ...,  78,   9, 137],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,  221,  ...,    5,   18,    5],\n",
            "        [ 538, 1714,  371,  ...,   13,  103,   13],\n",
            "        ...,\n",
            "        [ 144,    1,    1,  ...,    1,    1,    1],\n",
            "        [   4,    1,    1,  ...,    1,    1,    1],\n",
            "        [   3,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    4,   16,  176],\n",
            "        [ 648, 1188,  485,  ...,  388,   24,  102],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   76,    5,  ...,   18, 1180,    8],\n",
            "        [  66, 1143,   13,  ...,   25,    0, 1002],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,  113,    4,  ...,   16,  956,    4],\n",
            "        [  24,   24,    9,  ...,  104, 3747,  719],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([25, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  65,    8,   17,  ...,    5,    5,    5],\n",
            "        [ 469,   36,   73,  ..., 3250,  116,   70],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 63,   4,   7,  ...,   4,   4,   4],\n",
            "        [ 22,  38,  19,  ..., 132, 485,  53],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([37, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,   5,  ...,   5,   5,   5],\n",
            "        [ 25,  36, 385,  ...,  70, 329,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([40, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,   4,   4],\n",
            "        [ 33,  38, 122,  ...,  53,  59,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5, 105,   5,  ...,   5,   5,   8],\n",
            "        [986,  30, 452,  ..., 116, 538, 323],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4, 110,   4,  ...,   4,   4,   4],\n",
            "        [480,  30, 174,  ..., 154, 648, 355],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    8,  ...,    5,    5,    5],\n",
            "        [  13,   25,   36,  ...,   13, 3424,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4, 33,  4,  ...,  4,  4,  4],\n",
            "        [ 9, 37, 38,  ...,  9,  9,  9],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,   8,   5,  ...,   5,   5,   5],\n",
            "        [ 30,  13,  13,  ..., 538,   0,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,   4,  ...,   4,   4,   4],\n",
            "        [ 30,   9,   9,  ..., 648,   0,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,  18,   5,  ...,   8,   5,  30],\n",
            "        [113,  41,  66,  ...,  36,  66,  10],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4, 16,  4,  ...,  4,  4, 30],\n",
            "        [87, 19, 70,  ..., 38, 24, 11],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([25, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,  18,   8,  ...,   8,   8,   8],\n",
            "        [ 13, 544,  26,  ..., 955,  67,  16],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [2741,   16,    4,  ...,    4,    4,    4],\n",
            "        [   9,  362,   34,  ...,   31,   64,   14],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5, 1016,    5,  ...,    8,    5,    8],\n",
            "        [ 171,   52,   13,  ...,   16,   13, 2469],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4, 1254,    4,  ...,    4,    4,    4],\n",
            "        [  61,   17,    9,  ...,   14,    9, 5050],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([41, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,    5,    8,  ...,    5,    5,    5],\n",
            "        [  45,   13,   36,  ...,  766, 1410,  734],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([42, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  16,    4,    4,  ...,   21,    4,    4],\n",
            "        [  14,    9,   38,  ...,  106, 4714,  282],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  30,    5,    8,  ...,   18,    5,    8],\n",
            "        [   7, 3691,   67,  ...,  103,   13, 1430],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 30,   4,   4,  ...,  16,   4,   4],\n",
            "        [  6, 855,  64,  ...,  24,   9, 183],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [4472,    8,    5,  ...,    8,   54,   18],\n",
            "        [  22,   36,   13,  ...,   26,   74,  234],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    0,    1,    1],\n",
            "        [   1,    1,    1,  ...,    4,    1,    1],\n",
            "        [   1,    1,    1,  ...,    3,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [3387,    4,    4,  ...,    4,   19,   16],\n",
            "        [  12,   38,    9,  ...,   24,   41,  196],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  172,    1,    1],\n",
            "        [   1,    1,    1,  ...,    5,    1,    1],\n",
            "        [   1,    1,    1,  ...,    3,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   8,   5,  ...,  18,   8,   5],\n",
            "        [766,  36,  13,  ...,  30, 890,  70],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 21,   4,   4,  ...,  48,   4,   4],\n",
            "        [106,  38,   9,  ...,  19,  26,  53],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   3, 501,   1],\n",
            "        [  1,   1,   1,  ...,   1,   5,   1],\n",
            "        [  1,   1,   1,  ...,   1,   3,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 536,   18,    5,  ...,   18,   15,    5],\n",
            "        [ 182, 1857,  171,  ...,   45,  951,    0],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 145,   16,    4,  ...,   16,    7,    4],\n",
            "        [   9, 1870,   61,  ...,   14,  174, 1516],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([36, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,  503,  ...,    5,    8,    8],\n",
            "        [  26,   13,   57,  ...,  842,   16, 1591],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    9, 1012,  ...,    4,   14,    4],\n",
            "        [  34,    6,   37,  ...,  429,  646,  183],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   41,    8,  ...,   18,   43, 1586],\n",
            "        [ 986,  137,   36,  ...,  544,  103,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([39, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  19,   4,  ...,  16,  48,   9],\n",
            "        [480,  17,  38,  ..., 362,  53,   6],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,  18,  39,  ...,   5,   5,   8],\n",
            "        [ 16, 121,  49,  ...,  13,   0,  16],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   16,    7,  ...,    4,    4,    4],\n",
            "        [ 183,  112,   55,  ...,    9, 1287,   14],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([35, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,   18,  ...,    5,    5,  691],\n",
            "        [ 673,   26, 2466,  ...,   13,   25,  279],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,   16,  ...,    4,    4,  850],\n",
            "        [   9,   34, 4580,  ...,    9,   24,   17],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,   5,  18,  ...,  17,   8,  18],\n",
            "        [ 45,  13, 902,  ..., 413,  26,  54],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,  16,  ...,   7,   4,  16],\n",
            "        [ 50,   9,  19,  ..., 457,  24,  19],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([34, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,   76,   15,  ...,   18,   73,   76],\n",
            "        [  16,   45, 3172,  ...,   26,   74, 1143],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([38, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,  113,    4,  ...,   16,   19,  113],\n",
            "        [  14,   14,  127,  ...,   24,   41, 2070],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([34, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,   43,  ...,    5,    8,    8],\n",
            "        [1928,   47, 2168,  ...,   26,  323,   36],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,   48,  ...,    4,    4,    4],\n",
            "        [2439,   14,  168,  ...,   34,  355,   38],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,   18,  ...,    5,    5,    5],\n",
            "        [  16, 3889,  103,  ...,   13,  468,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 46,   4,  16,  ...,   4,   4,   4],\n",
            "        [ 14, 163,  53,  ...,   9, 161,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([23, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5, 1628,  ...,    8,   43,    5],\n",
            "        [  26,   13,    7,  ...,   16,   65,   13],\n",
            "        ...,\n",
            "        [   1,    1,    4,  ...,    1,    1,    1],\n",
            "        [   1,    1,    3,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   7,    9, 1352,  ...,    7,   48,    4],\n",
            "        [  24,   11,    6,  ...,   14,   63,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,  18,   5,  ..., 191, 216,  76],\n",
            "        [168,  30,  13,  ...,  30,  26,  41],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  16,   4,  ..., 202, 251,   4],\n",
            "        [ 59,   9,   9,  ...,  30,  24,  38],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,  39,  30,  ...,   5,   8,   5],\n",
            "        [ 45,  49,  10,  ...,  13,  16, 130],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([25, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   7,  30,  ...,   4,   4,  21],\n",
            "        [ 50, 348,  11,  ...,   9,  14, 233],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [105,   8,   8,  ...,   5,  17,   8],\n",
            "        [ 41,  67,  36,  ...,  13,   0,  16],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,   7,   4],\n",
            "        [625,  64,  38,  ...,   9, 284,  14],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,  18, 216,  ..., 105,   5,   5],\n",
            "        [ 41,  45,  30,  ...,  30,  13, 336],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,  16, 251,  ..., 110,   4,   4],\n",
            "        [ 19,  50,  30,  ...,  30,   9, 267],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,   5,  ...,   5,   5,   5],\n",
            "        [ 13,  16,  13,  ...,  13, 114,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4,  4,  4,  ...,  4,  4,  4],\n",
            "        [ 9, 14,  9,  ...,  9, 26,  9],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   18,   39,  ...,   66,   18,    8],\n",
            "        [  70, 5367,  103,  ...,   49, 3662,   36],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   16,    7,  ...,   53,   16,    7],\n",
            "        [  53, 1729,   53,  ...,  348, 3222,   38],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([25, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,    5,    8,  ...,  111,    5,    5],\n",
            "        [  30,   13,   16,  ...,  108, 1050, 6265],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  16,    4,    4,  ...,  131,  209,    4],\n",
            "        [  30,    9,   14,  ...,   10,   10, 5054],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([37, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  39,    8,    5,  ..., 1071,    5,    5],\n",
            "        [  25,   16, 6924,  ...,   15,   13, 1004],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([35, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   7,  120,    4,  ..., 1115,    4,    4],\n",
            "        [  33,   13, 4883,  ...,   12,    9, 1801],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   30,    5,  ...,    5,    8,  105],\n",
            "        [  49,  137,   26,  ...,   70, 2222,   26],\n",
            "        ...,\n",
            "        [   1,    4,    1,  ...,    1,    1,    1],\n",
            "        [   1,    3,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   30,    4,  ...,   46,    4,  110],\n",
            "        [  55,   17,  530,  ...,   24, 1350,   24],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   5,  ...,   5,  43,   5],\n",
            "        [ 13, 241,  13,  ...,  25,  80,  96],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([25, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,  33,  48,   4],\n",
            "        [  9, 323,   9,  ..., 292, 127,  24],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,  18,   5,  ...,  18,   5,   5],\n",
            "        [130, 544, 114,  ..., 121,  13,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 21,  16,   4,  ...,  16,   4,   4],\n",
            "        [115, 362,  26,  ..., 112,   9,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   5],\n",
            "        [  1,   1,   1,  ...,   1,   1,   3],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,    5,  ...,   18, 1071,    8],\n",
            "        [1341,   13,   49,  ...,   25,   44,   36],\n",
            "        ...,\n",
            "        [   1,    1,   72,  ...,    1,    1,    1],\n",
            "        [   1,    1,    4,  ...,    1,    1,    1],\n",
            "        [   1,    1,    3,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,   16, 1115,    4],\n",
            "        [ 530,    9,   55,  ...,  104,   12,   38],\n",
            "        ...,\n",
            "        [   1,    1,  288,  ...,    1,    1,    1],\n",
            "        [   1,    1,    5,  ...,    1,    1,    1],\n",
            "        [   1,    1,    3,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([34, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,  18,   8,  ...,   8,   5,   5],\n",
            "        [ 49,  45,  16,  ...,  67,  26, 502],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([35, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  16,   4,  ...,   4,   4,   4],\n",
            "        [ 55, 666,  14,  ...,  64,  34, 510],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([24, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,  105,    8,  ...,  389,   18,   59],\n",
            "        [ 130,   30, 6529,  ...,  144,  121,   14],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  21,  110,    4,  ...,  490,   16,   21],\n",
            "        [ 115,   30, 1501,  ...,  173,  112,  255],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   17,    5,  ...,    5,    8,    5],\n",
            "        [  32, 1833,   70,  ...,   13,   16,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    7,    4,  ...,    4,   14,  161],\n",
            "        [  35,   24,  386,  ..., 4224,    6,   22],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   8,   5,  ...,   5,   5,   5],\n",
            "        [ 36,  67,  66,  ...,  13,  13, 687],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,   4,   4],\n",
            "        [ 38,  64,  53,  ...,   9,   9, 795],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,  98,   1,   1],\n",
            "        [  1,   1,   1,  ...,   5,   1,   1],\n",
            "        [  1,   1,   1,  ...,   3,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([34, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,    5,  ...,    5,    5,    8],\n",
            "        [  16, 4064,   32,  ..., 5231,   13,   16],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([40, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,   21,    4,    4],\n",
            "        [  14,    9,   35,  ..., 4514,    9,   14],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([36, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,  18,  ...,  18,   8,   7],\n",
            "        [ 13,  36, 269,  ...,  30,  67,   6],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([41, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,   16,  ...,   16,   64, 1870],\n",
            "        [   9,   38,  215,  ...,   30, 1572,  359],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([25, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   5,  ...,  13,   5,  18],\n",
            "        [  0, 777,  25,  ...,  68,  13,  54],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    9,    4,  244],\n",
            "        [ 354,  161,   33,  ..., 1040,    9,   17],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   18,    5,  ...,    8,    5,    8],\n",
            "        [  13, 1692, 1152,  ...,   16,   70,   16],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   16,    4,  ...,    4,    4,   14],\n",
            "        [   9,   61, 3654,  ...,   14,   24,    6],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  17,    8,    5,  ...,    5,    5,    5],\n",
            "        [  36,   16,   13,  ..., 3209,  468,  114],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  7,   4,   4,  ...,   4,   4,   4],\n",
            "        [ 38,  14,   9,  ..., 240, 161,  26],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,  15,   5,  ..., 105,   5,   8],\n",
            "        [241,  13,  13,  ..., 236,  13,  36],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   7,   4,  ..., 110,   4,   4],\n",
            "        [977,   9,   9,  ...,  18,   9,  38],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 41, 537,   5,  ...,   5,   8,   5],\n",
            "        [ 52,  12,  70,  ...,  13,  16,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([35, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 19, 660,   4,  ...,   9,   4,   4],\n",
            "        [ 17,   8,  53,  ...,  11,  14,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    5,  ...,    8,  492,    5],\n",
            "        [  26,   36,  116,  ...,   36, 2058,   26],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    4,   21,    4],\n",
            "        [  34,   38,  154,  ...,   38, 3274,   34],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 41,   5,  43,  ...,   5,   5,   5],\n",
            "        [724,  66,  65,  ...,  13, 150,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [19,  4, 48,  ...,  4,  4,  4],\n",
            "        [78, 24, 63,  ...,  9, 25,  9],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,   18,   18,  ...,   18, 1700,    5],\n",
            "        [ 174,   30,   30,  ..., 1050, 1846,   66],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  21,   16,   16,  ...,   16, 1629,    4],\n",
            "        [ 233,   30,   30,  ..., 1611,   17,   70],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,   18,    5,  ...,   18,    8,    5],\n",
            "        [ 709,   73,   13,  ...,  371, 2642,  171],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,  16,   4,  ...,  16,   4,   4],\n",
            "        [666,  19,   9,  ..., 123, 267,  61],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   8,  ...,   5,   5,   5],\n",
            "        [ 13,   0,  36,  ...,  36, 551, 171],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,   4,   4],\n",
            "        [  9,   0,  38,  ...,  38, 122,  61],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,   18,    5,    5],\n",
            "        [  13,  558, 5330,  ...,  103,   13,   70],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  46,   4,  ...,  16,   4,   4],\n",
            "        [  9,  29, 369,  ...,  24,   9,  53],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,   5,   5,  ...,   5,  18,   5],\n",
            "        [ 65, 227,  13,  ...,  32,  45,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([37, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,   9,  ...,   4,  16,   4],\n",
            "        [ 63, 262,   6,  ...,  35, 666,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,    5,  ...,   18,  103,    8],\n",
            "        [ 323,   13,   13,  ...,   41,   25, 4797],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,  16,  24,   4],\n",
            "        [355,   9,   9,  ...,  19, 104, 120],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   5,  ...,   5,   5,  96],\n",
            "        [ 13,  13, 766,  ...,  13,  13, 493],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,  21,  ...,   4,  46,  24],\n",
            "        [  9,   9, 106,  ...,   9,   9, 387],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   76,    5,  ...,    5,    8,   18],\n",
            "        [  13,   41, 5986,  ...,   13,  274,  541],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  38,   4,  ...,   4,   4,  16],\n",
            "        [  9,  12,  99,  ...,   9, 122, 415],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,   13,  ...,    5,  298,   18],\n",
            "        [ 364,  502, 2163,  ...,  150,   12,   80],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([36, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,  174,  ...,    4,  216,   16],\n",
            "        [ 496,  510, 2539,  ...,   25,  323,  127],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,   8,  ...,  15,   8,  18],\n",
            "        [ 13,  36, 315,  ...,  32,  16,  30],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,  106,  ...,    7,    4,   16],\n",
            "        [   9,   38,  642,  ...,   35, 2614,   30],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 43,  18,  43,  ...,   8,   8,   5],\n",
            "        [  0, 503, 541,  ..., 364,  16,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 48,  16, 681,  ...,   4,   4,   4],\n",
            "        [699, 946, 415,  ..., 496,  14,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  17,    5,   17,  ...,    0, 1904,    5],\n",
            "        [ 523,   13,  523,  ...,  711,   41,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   7,    4,    7,  ...,  690, 1146,    4],\n",
            "        [  16,    9,   16,  ...,    0,   19,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([38, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    5,  ...,    8,   17,   15],\n",
            "        [3424,  955, 1010,  ...,   16,   67,   26],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([36, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    4,  209,    7],\n",
            "        [   9,   31, 1623,  ...,   14,   64,   34],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [105,   8,   5,  ...,  30,   8,  17],\n",
            "        [ 30,  36,  11,  ...,  57, 168,  16],\n",
            "        ...,\n",
            "        [  1,   3,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([36, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [110,   4,   4,  ...,  30,   4,   7],\n",
            "        [ 30,  38,  55,  ...,  37,  59,  14],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([36, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    0,    5,  ...,    5,    8,    5],\n",
            "        [  13, 1008,  502,  ...,  164,  174,   49],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([38, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4, 1487,    4,  ...,    4,  115,   55],\n",
            "        [   9, 1332,  510,  ...,  153,   14,    6],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,    5,    5,   18],\n",
            "        [  13,   13,   13,  ...,  150, 2710,  308],\n",
            "        ...,\n",
            "        [  48,    1,    1,  ...,    1,    1,    1],\n",
            "        [   4,    1,    1,  ...,    1,    1,    1],\n",
            "        [   3,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  9,   4,   4,  ...,   4,  30,  16],\n",
            "        [  6,   9,   9,  ...,  25, 102,  99],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([25, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 70,  39,   5,  ..., 216,   5,   8],\n",
            "        [ 26, 103, 371,  ...,  41,  32,  36],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 53,   7,   4,  ..., 251,   4,   4],\n",
            "        [ 34,  53, 123,  ...,  19,  35,  38],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([37, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,   5,   8,  ...,  18,   8,  18],\n",
            "        [ 65,  13,  16,  ...,  45,  16, 925],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([36, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,   4,  ...,  16,   4,  16],\n",
            "        [ 63,   9,  14,  ...,  50,  14, 106],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    8,   43,  ...,    8,    8,   18],\n",
            "        [1635,  161,    0,  ...,   26,   16, 1459],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,  14,  16],\n",
            "        [163,  14,  94,  ...,  24,  37, 353],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([37, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 692,   18,  572,  ...,    8,    5,    5],\n",
            "        [  16,    0,   10,  ...,   16,   13, 4000],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,  290,    1],\n",
            "        [   1,    1,    1,  ...,    1,    4,    1],\n",
            "        [   1,    1,    1,  ...,    1,    3,    1]], device='cuda:0')\n",
            "trg: (torch.Size([36, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 133,   16,    4,  ...,    4,    4,    4],\n",
            "        [  14, 1133,  665,  ...,   14,    9, 1930],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,  143,    1],\n",
            "        [   1,    1,    1,  ...,    1,    5,    1],\n",
            "        [   1,    1,    1,  ...,    1,    3,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  0,   8,   8,  ...,   8,   5,   5],\n",
            "        [ 73,  67, 274,  ..., 360,  70,  49],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,  176,    4,    4],\n",
            "        [  87, 4280,  122,  ...,   10,   70,   55],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,   18,   15,  ...,    5,    5,    5],\n",
            "        [  16,   30,    0,  ...,   13, 1384,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  21,   16,    7,  ...,    4,    4,    9],\n",
            "        [  14,   30, 2845,  ...,    9, 1888,    6],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  17,    8,   15,  ...,    5, 4301,    5],\n",
            "        [  16,   16, 3530,  ...,  725,    9,  580],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   7,    4,    7,  ...,   21,    0,    4],\n",
            "        [  14,   14,   25,  ..., 1839,   15,  674],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,   5, 492,  ...,   5,  15,   5],\n",
            "        [ 30,  13,  16,  ..., 580, 515,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([25, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4, 209,  ...,   4,   7,   4],\n",
            "        [778,   9,  14,  ..., 674,  61,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8, 5387,  ...,   18,    8,    5],\n",
            "        [  25,   16,    3,  ...,   41,   16,   66],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4, 186,  24,  ...,  16,   4,   4],\n",
            "        [ 33,  74, 104,  ...,  19,  14,  53],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,  65,  ...,   5,   5,   5],\n",
            "        [ 13,  13, 126,  ..., 130,  25,  96],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,  63,  ...,  21,   4,  24],\n",
            "        [  9,   9,  17,  ..., 115,  33,  31],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  41,    8,  833,  ...,  980,    5,    5],\n",
            "        [   7,   16, 6741,  ...,   74,  164,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 19,   4, 963,  ...,  19, 153,   4],\n",
            "        [  6,  14,   0,  ..., 673,   6,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 109,    5, 1222,  ...,    8,    5,    8],\n",
            "        [1433,   13,   48,  ..., 1087, 1743,  230],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,  209,  ...,   21,    4,    4],\n",
            "        [   9,    9,   10,  ...,  324, 2559,  200],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 39,  91,   5,  ...,   5,   8,   5],\n",
            "        [ 49,  11,   0,  ...,  13,  16, 164],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  7,   7,   4,  ...,   4,   4,   4],\n",
            "        [ 55,  88, 239,  ...,   9,  14, 153],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([36, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,   41,    5,  ...,    5,    8,    5],\n",
            "        [  16,  170, 7137,  ...,  129, 3325, 2369],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    9,    4,  ...,   16,    4, 1922],\n",
            "        [  14,    6, 1238,  ..., 1649, 1212,    6],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  186,    1,    1],\n",
            "        [   1,    1,    1,  ...,    5,    1,    1],\n",
            "        [   1,    1,    1,  ...,    3,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    8,  ...,    5, 4472,    5],\n",
            "        [  13,   16, 2560,  ...,   13,   22,   32],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   14,  667,  ...,    4, 3387,    4],\n",
            "        [   9,   41, 1197,  ...,    9,   12,   35],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   5,  ...,   8,  18,   5],\n",
            "        [ 13,  13, 457,  ..., 323, 103,  26],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,  16,   4],\n",
            "        [  9,   9,  62,  ..., 355,  53,  34],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,   18,   18,  ...,    8,    5,    5],\n",
            "        [1430,   25,   30,  ...,   36,   13,  777],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([33, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   16,   16,  ...,    4,    4,    4],\n",
            "        [ 910,   24, 1397,  ...,   38,    9,  161],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([34, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [18,  5,  5,  ...,  8,  8,  5],\n",
            "        [ 0, 13, 13,  ..., 36, 36, 13],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,   4,  ...,   4,   4,   4],\n",
            "        [  0,   9,   9,  ...,  38, 237,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   8,  ...,  18,   5,   5],\n",
            "        [ 13, 251,  16,  ...,  30,  13,  66],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4,  4,  4,  ..., 16,  4,  4],\n",
            "        [ 9, 31, 14,  ..., 30,  9, 53],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([38, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,    5,    5,    5],\n",
            "        [5533,   32,   32,  ...,   13,   96,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([43, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4,  4,  4,  ...,  4, 24,  4],\n",
            "        [30, 35, 35,  ...,  9,  9,  9],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,  18,   8,  ...,   5,  76,   8],\n",
            "        [909,  65,  36,  ...,  13,  41,  16],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  16,   4,  ...,   4,   0,   4],\n",
            "        [735,  63,  38,  ...,   9, 190,  14],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   54,    5,  ...,    5,  105,   18],\n",
            "        [  13,  724,   13,  ..., 7407,   30,   30],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  19,   4,  ...,   4, 110,  16],\n",
            "        [  9,  17,   9,  ..., 316,  30,  30],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  54,    5,    5,  ...,   18,    5,    5],\n",
            "        [ 157,   70, 6250,  ..., 1459,   13,   25],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  19,    4,    4,  ...,   16,    4,    4],\n",
            "        [  17,   53, 2932,  ...,  353,    9,   33],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,  18,   8,  ...,   5,   8,  18],\n",
            "        [ 25, 544,  16,  ...,  13,  16,  30],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  16,   16,    4,  ...,    4,    4,   16],\n",
            "        [ 104, 2558,   14,  ...,    9,   14,   30],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 413,    8,   18,  ...,  105,    5,    5],\n",
            "        [  73, 3851,   26,  ...,   25,  272,   25],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 457,    4,   16,  ...,  110,  145,    4],\n",
            "        [  19, 2967,   24,  ...,  104,    9,   33],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    8,    5,  ...,    5,    5,   18],\n",
            "        [7112,  274,   70,  ..., 1332,  164,  537],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,   4,  16],\n",
            "        [  0, 122,  53,  ..., 170, 153, 660],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([25, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,    5,   43,  ...,   18, 7091,    5],\n",
            "        [  65,   13,   41,  ...,  121,   20,   13],\n",
            "        ...,\n",
            "        [   1,    1,   37,  ...,    1,    1,    1],\n",
            "        [   1,    1,    4,  ...,    1,    1,    1],\n",
            "        [   1,    1,    3,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  16,    9,   48,  ...,   16,   99,    4],\n",
            "        [ 196, 1031,   19,  ...,  112, 1461,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,    5,  ...,    8,    5,   18],\n",
            "        [  26, 7201,   70,  ..., 1047,  568,   30],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ..., 369,   4,  16],\n",
            "        [ 24,  26,  70,  ...,  14, 362,  30],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   43,    5,  ...,    5,    5,    5],\n",
            "        [  13,   41, 4066,  ...,   13,   13,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 46,  48,   4,  ...,   4,   4,   4],\n",
            "        [  9,  19, 978,  ...,   9,   9,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([34, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   8,  ...,   8,   5,  18],\n",
            "        [717,  26, 165,  ...,  26,  13,  30],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [176,   4,   4,  ...,   4,   4,  16],\n",
            "        [ 17,  34, 120,  ...,  24,   9,  30],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,  39,   5,  ...,   5,   8,  18],\n",
            "        [ 30, 103, 164,  ..., 195, 364,   0],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  16,    7,    4,  ...,    4,    4,   16],\n",
            "        [  30,   70,  153,  ...,  198, 1197,    0],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,   18,   25,    8],\n",
            "        [2051,  766,   13,  ...,   30,  141,   16],\n",
            "        ...,\n",
            "        [   1,    4,    1,  ...,    1,    1,    1],\n",
            "        [   1,    3,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [327,  21,   4,  ...,  16,  24,   4],\n",
            "        [ 67, 106,   9,  ...,  30, 104,  14],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,   5,  ...,   8,   5,   8],\n",
            "        [ 26,  36, 385,  ...,  36, 150,  36],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([25, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 34,   4,   4,  ...,   4,   4,   4],\n",
            "        [ 13,  38, 122,  ...,  38,  25,  38],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,   18,    8,  ...,   39,    8,    5],\n",
            "        [ 315,  103, 1002,  ...,   25,   36, 1378],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 21,  16,   4,  ...,   7,   4,   4],\n",
            "        [106,  53, 719,  ...,  33,  38, 178],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([23, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,  45,  43,  ...,   5, 221,   5],\n",
            "        [ 16,   9,   0,  ...,  13,  41,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   3,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([25, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [14, 50, 48,  ...,  4, 74,  4],\n",
            "        [56,  0,  0,  ...,  9, 19,  9],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,  12,   8,  ...,  18,   5,   8],\n",
            "        [ 16,   6, 103,  ...,  65, 173,  16],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4,  8,  4,  ..., 16,  4,  4],\n",
            "        [14,  4, 70,  ..., 63, 26, 14],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    5,  ...,    8,    8,    8],\n",
            "        [ 272, 3723,   13,  ...,   16,  168,  165],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 21,   4,   4,  ...,   4,   4,   4],\n",
            "        [145, 371,   9,  ...,  14, 381, 120],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,   65,    5,  ...,   30,    8,   18],\n",
            "        [  26, 5366,  538,  ...,   10,   67,   65],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  63,   4,  ...,  30,   4,  16],\n",
            "        [ 24, 673, 648,  ...,  11,  64,  63],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    5,  ...,    5,    8,    5],\n",
            "        [  13,   16,  618,  ..., 4400,   16,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    4,    4,    4],\n",
            "        [   9,   14,  467,  ..., 3307,   14,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([24, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   18,    5,  ...,    8,    5,    8],\n",
            "        [ 580,  121,  298,  ..., 6815,   25,   16],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([24, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  16,   4,  ...,  46,   4,   4],\n",
            "        [674, 112, 216,  ..., 183,  33,  14],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,   8,  ...,   5,  18,   5],\n",
            "        [177, 131,  16,  ...,  26,  80, 130],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,  16,  21],\n",
            "        [ 24,  14,  14,  ...,  34, 127, 233],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,  18,   5,  ..., 221,  54,   8],\n",
            "        [ 13, 121, 114,  ...,  54,  53,  26],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  16,   4,  ..., 113,  19,   4],\n",
            "        [  9, 112,  26,  ...,  19,  32,  24],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,   8,   5,  ...,  39,  43,   8],\n",
            "        [ 30,  16,  25,  ...,   0, 243,  26],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [16,  4,  4,  ...,  7, 48,  4],\n",
            "        [30, 14, 33,  ...,  0, 26, 24],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,    5,    5,  ...,    5, 1976,   18],\n",
            "        [ 121, 3614,   26,  ...,  114,   30,   30],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,   4,  ...,   4, 133,  16],\n",
            "        [112, 188,  34,  ...,  26,  30,  30],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   18,    8,  ...,    5,    5,    5],\n",
            "        [  13,   30,   16,  ...,   96, 2550,  568],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   16,    4,  ...,    4,    4,    4],\n",
            "        [   9,   30,   14,  ...,   24, 1739,  362],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 5,  5,  5,  ...,  8,  8,  5],\n",
            "        [70, 13, 32,  ..., 16, 16, 13],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,   4,   9],\n",
            "        [ 24, 168,  35,  ...,  14,  14,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([24, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,   5,  ...,   5,  18,   8],\n",
            "        [ 13,  67,  13,  ..., 493,  30,  26],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([24, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,  21,  16,   4],\n",
            "        [  9,  64,   9,  ..., 387,  30,  24],\n",
            "        ...,\n",
            "        [  1,   1,   3,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  30,    8,    8,  ...,   18,    8,    5],\n",
            "        [1426,   66, 5934,  ...,   30,   16,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([25, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  30,    4,    4,  ...,   16,  120,    4],\n",
            "        [1243,   24,  443,  ...,   30,  169,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([34, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,   17,    8,  ..., 4711,    8,    5],\n",
            "        [  16,   18,   16,  ...,   22,   16,  385],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   7,   4,  ...,   4,   4,   4],\n",
            "        [ 14,  16,  14,  ...,  59, 120, 122],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,  18,  ...,  43,  65,   5],\n",
            "        [ 13,  16,  41,  ..., 121,  57,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([35, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,  16,  ...,  48,  63,   4],\n",
            "        [  9,  14,  19,  ..., 112,  37,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8, 416,  ...,   5,   8,  76],\n",
            "        [ 49, 152,   0,  ...,  13,  67,  41],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4, 549,  ...,   4,   4,  19],\n",
            "        [ 55, 862, 783,  ...,   9,  64, 373],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([45, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   39,    8,  ...,    8,    5,    8],\n",
            "        [1586,  103,  174,  ...,   16,   13,   16],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([41, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   7,  21,  ...,   4,   4,   4],\n",
            "        [  9,  53, 115,  ...,  14,   9,  14],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,   5, 600,  ...,   5, 492,   5],\n",
            "        [ 25, 299,  41,  ...,  25, 323,  49],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([25, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4, 522,  ...,   4, 209,   4],\n",
            "        [104, 357,  19,  ...,  24, 355,  55],\n",
            "        ...,\n",
            "        [  1, 500,   1,  ...,   1,   1,   1],\n",
            "        [  1,   5,   1,  ...,   1,   1,   1],\n",
            "        [  1,   3,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 76,   8,   8,  ...,   5,   5,  18],\n",
            "        [ 65,  67,  67,  ...,  25, 537, 269],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 113,    4,    4,  ...,    4,    4,   16],\n",
            "        [  63,   64,   64,  ...,   33, 1093,  215],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([34, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,   18,  ...,    5,    5,   18],\n",
            "        [  13, 2168,  352,  ...,   13,   13,  103],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  21,  16,  ...,   4,   4,  16],\n",
            "        [  9, 937, 492,  ...,   9,   9,  53],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   15,    5,  ...,    5,  980,   18],\n",
            "        [  66,  103, 2859,  ..., 6038,   27,   80],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([24, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    7,    4,  ...,    4,   19,   16],\n",
            "        [  24,   53,  667,  ..., 1888,  152,  127],\n",
            "        ...,\n",
            "        [   1,    1,    3,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 8, 73,  8,  ..., 27, 43,  5],\n",
            "        [36,  9, 36,  ...,  6, 25,  0],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   19,    4,  ...,  236,   48,    4],\n",
            "        [  38, 1550,   38,  ...,    4,  104, 5390],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([38, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,    5,    5,  ...,  271,    5,    5],\n",
            "        [ 121,   25,   66,  ..., 2082,   13,  116],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([37, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,   4,  ...,  63,   4,   4],\n",
            "        [112,  33,  53,  ...,  15,   9, 154],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 65,   8,   5,  ...,   5,   8,   5],\n",
            "        [579,  56, 150,  ..., 177,  16,  96],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [63,  4,  4,  ...,  4,  4,  4],\n",
            "        [17, 38, 25,  ..., 24, 14, 24],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,   18,    5,   17],\n",
            "        [  13,   25,   13,  ...,   80,   66, 2944],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 2145,    1,    1],\n",
            "        [   1,    1,    1,  ...,    4,    1,    1],\n",
            "        [   1,    1,    1,  ...,    3,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   16,    4,  ...,   16,    4,    4],\n",
            "        [   9,   63,    9,  ...,  127,   24, 2544],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,  833,    1,    1],\n",
            "        [   1,    1,    1,  ...,    5,    1,    1],\n",
            "        [   1,    1,    1,  ...,    3,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,    8,   54,   18],\n",
            "        [  13,  572,  241,  ...,   16, 2995,   30],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    4,   19,   16],\n",
            "        [   9,  665,  323,  ...,   14, 2388,   30],\n",
            "        ...,\n",
            "        [   5,    1,    1,  ...,    1,    1,    1],\n",
            "        [   3,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([35, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   5,  ..., 390,   5,   5],\n",
            "        [ 13,  13,  32,  ...,  16,  13,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([40, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ..., 145,   4,   4],\n",
            "        [  9, 168,  35,  ...,  14,   9,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,    5,    5,    5],\n",
            "        [1880,   49,   13,  ...,   49,   96, 2485],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([25, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,  46,   4,   4],\n",
            "        [153,  55,   9,  ..., 348,  53, 762],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,   18,    5,  ...,   41,    5,   15],\n",
            "        [  26,  103,   13,  ..., 1262,   13,   26],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  16,   4,  ...,  19,   4,   7],\n",
            "        [ 24,  70,   9,  ..., 304,   9,  34],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   5,   5,  ...,  18,   8,   5],\n",
            "        [  0, 130,  13,  ...,  54,  36, 522],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   21,    4,  ...,   16,    4,    4],\n",
            "        [2861,  115,    9,  ...,   19,   38,   26],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,    5,    5,    5],\n",
            "        [  13, 1253,   13,  ...,   13,   13,  385],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    4,    4,    4],\n",
            "        [   9, 1067,    9,  ...,    9,    9,  122],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([23, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,    5,    5,    5],\n",
            "        [  13,   13,    0,  ..., 1010,  272,  863],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([25, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    4,   21,    4],\n",
            "        [   9,    9, 5755,  ...,  812,  145,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 8, 18, 18,  ...,  8, 43,  5],\n",
            "        [ 0, 25, 41,  ..., 36, 30, 13],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  16,  16,  ...,   4,  48,   4],\n",
            "        [166, 104,  19,  ...,  38,  30,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    5,  ..., 4173,   18,   17],\n",
            "        [  13,   36,  173,  ..., 3556,   30,   43],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([37, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   9,    4,    9,  ...,  246,   16,    7],\n",
            "        [  73,   38,   73,  ..., 3813,   30,   48],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([24, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  47,   18,    8,  ...,    5,    8,   18],\n",
            "        [   6,  241,    0,  ...,   13, 4259,   30],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  16,   4,  ...,   9,  21, 176],\n",
            "        [  9, 228, 183,  ...,   6, 324,  17],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   0,  18,  ...,   5,  18,   5],\n",
            "        [ 16,   7, 890,  ...,  49,   0, 689],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4, 4125,   16,  ...,    4,   16,    4],\n",
            "        [  14,  252,   26,  ...,   55,  183,   52],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([37, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,  43, 191,  ...,  17,   5,   5],\n",
            "        [ 13,  25,  41,  ...,  18,  13,  70],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   48,  202,  ...,    7, 1875,    4],\n",
            "        [ 524,  104,   19,  ...,   16,    8,   70],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,   26,    7,  ...,   15,    5, 1326],\n",
            "        [7231, 2400,   82,  ..., 1485,   13,   11],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,  34,  19,  ...,   7,   4,  53],\n",
            "        [355, 669,  73,  ...,  86,   9, 238],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  76,    8,    8,  ...,   54,    5,    5],\n",
            "        [1700,   36, 5546,  ...,   11,   96,   70],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([36, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 113,    4,   14,  ...,   19,    4,    4],\n",
            "        [1227,   38, 2254,  ...,    6,   24,   53],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([22, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,    5,    5,  ...,    7,    5,    5],\n",
            "        [  30,   66,  632,  ...,    6,   13, 2844],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([23, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,   4,  ...,   6,   4,   4],\n",
            "        [ 30,  70, 732,  ...,   4,   9, 282],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([35, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,   8,  ...,   8,   5, 105],\n",
            "        [130,  16, 130,  ...,  16,  13,  54],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([35, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 21,   4,  21,  ...,   4,   4, 110],\n",
            "        [115,  14, 115,  ...,  14,   9,  19],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,  216,    8,  ...,   18,    8,   18],\n",
            "        [3881,   30,   16,  ...,   45,   16,  537],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  46,  251,    4,  ...,   16,    4,   16],\n",
            "        [3417,   30,   14,  ...,   50,   14,  660],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   5,   5,  ...,   5,   8,   8],\n",
            "        [  0,  26,  13,  ...,  13,  16, 253],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,  28,   4,   4],\n",
            "        [235,  34,   9,  ...,  32,  14,  25],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([45, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   8,  ...,   8,  18,   5],\n",
            "        [ 13,  13,  16,  ..., 113,  65,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([42, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4, 46,  4,  ...,  4, 16,  4],\n",
            "        [ 9,  9, 14,  ..., 87, 63,  9],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,  76,   5,  ..., 105,   5,   5],\n",
            "        [ 66,  26,  66,  ...,  41,  13,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4, 113,   4,  ..., 110,   4,   4],\n",
            "        [ 53,  24,  24,  ...,  19,   9, 174],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([24, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 5,  5, 15,  ...,  8,  5, 18],\n",
            "        [49, 13,  0,  ..., 16, 13, 26],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "trg: (torch.Size([24, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4,  4,  7,  ...,  4,  4, 16],\n",
            "        [55,  9,  0,  ..., 14,  9, 24],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,  14,   5,  ...,   5,   5,   5],\n",
            "        [618,  16,  13,  ...,  13,  13,  32],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  16,    4,    4,  ...,    4,    4,    4],\n",
            "        [1282,   14,    9,  ...,    9,    9,   35],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,    5,    8,  ...,    5,   41,    5],\n",
            "        [  45,  150, 1919,  ...,  241,  170,   25],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([36, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  16,   25,  183,  ...,    4,   19,    4],\n",
            "        [  50,    9, 1534,  ...,  323,  201,   33],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,   18,  216,  ...,   98,    5,    5],\n",
            "        [  45, 1876,  490,  ...,   14, 1049,   96],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  16,   16,  251,  ...,  113,    4,    4],\n",
            "        [  50, 2839,  932,  ...,  784,  480,   24],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   7,    5,    5,  ...,   76,    5,    5],\n",
            "        [   6,   66,   13,  ...,   41,   32, 5724],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([33, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 6,  4,  4,  ..., 19,  4,  4],\n",
            "        [ 4, 24,  9,  ..., 13, 35, 61],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,  18,  ...,   8,   8,   8],\n",
            "        [ 26,  13,  54,  ..., 165,  16,  16],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,  16,  ..., 120,   4,   4],\n",
            "        [ 34,   9,  19,  ..., 165,  14,  14],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,   76,  ...,    5,    8,    5],\n",
            "        [  36,   13,   41,  ..., 3531,   16,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4, 113,  ...,   4,   4,   9],\n",
            "        [ 38,   9,  19,  ...,  25,  14,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([36, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 105,    5,    5,  ...,    5,    5,    5],\n",
            "        [ 503, 5251,  173,  ..., 1110,   13,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([37, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 110,   46,    4,  ...,    4,    4,    4],\n",
            "        [ 946, 3010,    9,  ...,  133,    9,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([35, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    5,  ...,    8,  625,   18],\n",
            "        [  13,  168,   25,  ...,   67, 1870,   41],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4, 602,  16],\n",
            "        [  9,  59,  33,  ...,  64,   9,  19],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [1226,    5,    5,  ...,    5,    5,   43],\n",
            "        [  52, 2160,   49,  ...,  555,   13,   41],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    4,    1],\n",
            "        [   1,    1,    1,  ...,    1,    3,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [3046,    4,    4,  ...,    4,    4,   48],\n",
            "        [  20, 1435,   55,  ...,    9,    9,   19],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,   76,  ...,   18,    5,   73],\n",
            "        [  49, 2101,   41,  ..., 1065, 3285,   20],\n",
            "        ...,\n",
            "        [   1,    0,    1,  ...,    1,    1,    1],\n",
            "        [   1,    4,    1,  ...,    1,    1,    1],\n",
            "        [   1,    3,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([35, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,  176,   19,  ...,   16,    4,   19],\n",
            "        [  55,   10,    6,  ...,  127, 1466,   15],\n",
            "        ...,\n",
            "        [   1,  139,    1,  ...,    1,    1,    1],\n",
            "        [   1,    5,    1,  ...,    1,    1,    1],\n",
            "        [   1,    3,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   5,  18,  ...,   8,  43,   5],\n",
            "        [ 16,  70,  30,  ...,  36, 805,  66],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,  16,  ...,   4, 681,   4],\n",
            "        [ 14,  24,  30,  ...,  38, 486,  24],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,   12,  ...,   43,    8,   43],\n",
            "        [  96,   34,    6,  ..., 4987,   16,   65],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([35, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [176,   4, 217,  ...,  48,   4,  48],\n",
            "        [ 10,  39,  32,  ..., 399,  14,  63],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([34, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,  413,    8,  ...,    8,   18,    5],\n",
            "        [  36,  890, 7196,  ...,   16,   30,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4, 457,   4,  ...,   4,  16,   4],\n",
            "        [ 38,  26, 616,  ...,  14,  30, 975],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([25, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 655,    5,    5,  ...,    8,    5,    5],\n",
            "        [ 196, 1947,  171,  ...,   16,   13,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [3660,  667,    4,  ...,    4,    4,    4],\n",
            "        [  73,   15,   61,  ...,   14,    9,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,    5,    5,  ..., 1596,    5,    5],\n",
            "        [ 121,  502,   13,  ...,   12,   32,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,   4,  ...,  84,   4,   4],\n",
            "        [112, 510,   9,  ..., 523,  35,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5, 2084,    5,  ...,  600,    5,   70],\n",
            "        [  25,    0,   70,  ...,   41,   13, 1032],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,  699,    4,  ...,  522,    4,    4],\n",
            "        [  33, 2691,   53,  ...,   19,    9,   24],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [493,   0,   5,  ...,   5,   5,   5],\n",
            "        [ 13,  44,  13,  ...,  13,  26,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([33, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [161,   7,   4,  ...,   4,   4,   4],\n",
            "        [387, 182,   9,  ...,   9, 174, 388],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,    5,  ...,    8,    8,   15],\n",
            "        [  16,   13,   70,  ...,   36,   16, 1049],\n",
            "        ...,\n",
            "        [  45,    1,    1,  ...,    1,    1,    1],\n",
            "        [   4,    1,    1,  ...,    1,    1,    1],\n",
            "        [   3,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,   4,   7],\n",
            "        [ 14,   9,  53,  ...,  38,  14, 480],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8, 191,   8,  ...,   5,   5,   0],\n",
            "        [113,  41, 113,  ...,  70,  13,   0],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,   4,   0],\n",
            "        [ 87, 884,  38,  ...,  24,   9,   0],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([24, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [191,   5,   8,  ...,   5,   5,  65],\n",
            "        [243,  13,  67,  ...,  13,  49, 261],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [202,   4,   4,  ...,   4,   4,  63],\n",
            "        [ 26,   9,  64,  ...,   9,  24, 270],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   5,  ...,   5,   5,   5],\n",
            "        [493, 272,  26,  ...,  13, 568,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 21,  21,   4,  ...,   4,   4,   4],\n",
            "        [387, 145,  24,  ...,   9, 362,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   3],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,   76,    8,  ...,    5,    5,    5],\n",
            "        [  16, 4897,   36,  ...,  272,  161,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,  21,   9,   4],\n",
            "        [ 14,  38,  38,  ..., 145,  73,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 43,   8,  54,  ...,   7,   8,   5],\n",
            "        [ 41,  67, 394,  ...,   6, 168, 427],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 48,   4,  19,  ...,   4,   4,   4],\n",
            "        [450,  64, 483,  ..., 123,  59,  59],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   18,   18,  ...,   18,    8,   18],\n",
            "        [  96,   41,    7,  ...,   30, 4076,   65],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4, 16, 16,  ..., 16,  4, 16],\n",
            "        [24, 19, 24,  ..., 30, 14, 63],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   15,    0,  ...,   43,    5,   18],\n",
            "        [  25,  431,  204,  ..., 2637,  550, 2819],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  33,    7,    0,  ...,   48,   46,   16],\n",
            "        [4192,   64,   10,  ..., 1939,  224,   19],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 30,   5,   5,  ...,   5,  43, 105],\n",
            "        [ 53,  70,  13,  ...,  96,  30,  65],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 30,   4,   4,  ...,   4,  48, 110],\n",
            "        [ 32,  24,   9,  ...,  24,  30,  63],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,  54,  18,  ...,   5,  39,   5],\n",
            "        [951,  74,  54,  ...,  13,  25,  25],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   19,   16,  ...,    4,    7,    4],\n",
            "        [2253,  152,   19,  ...,    9,   33,   33],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   5,  ...,   5,   8,   5],\n",
            "        [ 66,   0, 537,  ...,  13,  16,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([25, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    4,    4,    4],\n",
            "        [  24,  183, 1093,  ..., 4800,   14,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 76,   8,   5,  ...,   8,   5,  15],\n",
            "        [ 41,  16,  66,  ...,  16, 298,  26],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [113,   4,   4,  ...,   4,   4,   7],\n",
            "        [ 19,  14,  53,  ...,  14, 216,  34],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([46, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [1628,    5,    5,  ...,   43,    5,    5],\n",
            "        [ 695,   13,   13,  ..., 1323,  164, 2158],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([37, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [1352,    4,    4,  ...,   48,    4,    4],\n",
            "        [1098,    9,    9,  ..., 3085,  153, 2178],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,   8,  ...,   5, 221,   5],\n",
            "        [150,  16,  67,  ...,  13,  54,  96],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4, 290,  ...,   4,  74,   4],\n",
            "        [ 25,  14,   6,  ...,   9,  19, 491],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [191,   5,  18,  ...,   5,   5,  45],\n",
            "        [ 54,  25,  30,  ...,  13,  13,  20],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [837,   4,  16,  ...,   9,   4,  50],\n",
            "        [ 12,  33,  30,  ...,   6,   9,   6],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  43,   18,    8,  ...,    5,    5,   18],\n",
            "        [  30,   30,   16,  ...,   13, 1529,   45],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 48,  16,   4,  ...,   9,  21,  16],\n",
            "        [ 30,  30,  14,  ...,   6, 253,  50],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([25, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,   43,  221,    5],\n",
            "        [ 130, 7798,   26,  ...,   30,   41, 1580],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  21,    4,   24,  ...,   48,   74,    4],\n",
            "        [ 115, 2369,   34,  ...,   30,   19,  510],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,   41,  ...,    8,   73,    5],\n",
            "        [   0,    7,   10,  ...,  103, 3296,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 21,   4,  19,  ...,   4,  19,   4],\n",
            "        [554,  64,  11,  ...,  70,  17,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   15,   18,  ...,   18,    5,   43],\n",
            "        [2158, 2567,   30,  ...,   41,  177,   30],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([32, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    7,   16,  ...,   16,    4,   48],\n",
            "        [2178, 3361,   30,  ...,   19,   24,   30],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   8,   5,  ...,   5,  39,   5],\n",
            "        [ 16, 168,  13,  ...,  13, 209,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,   7,   4],\n",
            "        [ 14,  59,   9,  ...,   9, 134,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,   17,    5,  ...,    8, 1609,    8],\n",
            "        [ 954,  105,   13,  ...,   36,   12,   36],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   7,   4,  ...,   4, 216,   4],\n",
            "        [198, 110,   9,  ...,  38, 245,  38],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,  727,  ...,    5,    5,    5],\n",
            "        [  13, 4798, 1432,  ...,   49,   26,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4, 521,  ...,   4,   4,   4],\n",
            "        [  9, 386,   0,  ..., 348,  24,   9],\n",
            "        ...,\n",
            "        [  1,   5,   1,  ...,   1,   1,   1],\n",
            "        [  1,   3,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([38, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,   76,  ...,    8,   18,    5],\n",
            "        [ 329,   13,   41,  ...,   16, 3745,  114],\n",
            "        ...,\n",
            "        [   1,    1,  169,  ...,    1,    1,    1],\n",
            "        [   1,    1,    4,  ...,    1,    1,    1],\n",
            "        [   1,    1,    3,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([37, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4, 113,  ..., 176,  16, 176],\n",
            "        [163,   9,  19,  ...,  10, 123,  10],\n",
            "        ...,\n",
            "        [  1,   1,  33,  ...,   1,   1,   1],\n",
            "        [  1,   1,   5,  ...,   1,   1,   1],\n",
            "        [  1,   1,   3,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,    8,    5, 1481],\n",
            "        [  13,   13,  496,  ...,   16,   13,   20],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,   4, 935],\n",
            "        [  9,   9,  31,  ...,  14,   9, 341],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  18,    5, 1222,  ...,    5,    5,   18],\n",
            "        [  30,   25,   48,  ..., 1010,  171,  174],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4, 832,  ...,   4,  61,  16],\n",
            "        [ 30,  33,  10,  ..., 812,  35, 233],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,   15,  ...,    8,    5,   76],\n",
            "        [5657,   66,   32,  ...,  709, 2225,   30],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    7,  ...,    4,   21,  113],\n",
            "        [3995,   53,   35,  ...,  183, 1397,   30],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    5,    1],\n",
            "        [   1,    1,    1,  ...,    1,    3,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,  221,    5,    8],\n",
            "        [  13,   13, 2969,  ...,  174,   13,  449],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([29, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,   74,    4,    4],\n",
            "        [ 168,    9, 2813,  ...,  115,    9,   14],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 72])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,   18,  ...,    5,   35,    5],\n",
            "        [ 330,   13,   30,  ..., 2859,   17,  130],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([25, 72])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 21,   4,  16,  ...,   4,  28,  21],\n",
            "        [387,   9,  30,  ..., 667, 427, 233],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [325,  18, 389,  ..., 105,   5,   5],\n",
            "        [ 29,  25, 466,  ...,  45,  49,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  46,   16,  490,  ...,  110,    4,    4],\n",
            "        [  64,  104, 1336,  ...,   50,   55,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 18,   5,   5,  ...,   5,   5,   5],\n",
            "        [ 45, 299,  13,  ...,  13, 177,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 16,   4,   4,  ...,   4,   4,   4],\n",
            "        [ 50, 357,   9,  ...,   9,  24,   9],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   6, 105,  ...,   5,   5,   5],\n",
            "        [  0,  80,  30,  ..., 502,  13,  13],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,  110,  ...,    4,    4,    4],\n",
            "        [3342,   24,   30,  ...,  510,    9,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 5,  8,  5,  ...,  5,  5,  8],\n",
            "        [13, 16, 66,  ..., 13, 66, 26],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 4,  4, 53,  ...,  4,  4,  4],\n",
            "        [ 9, 14, 33,  ...,  9, 53, 24],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  3],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    5,  ...,    8,    5,    5],\n",
            "        [3951,   36, 6544,  ...,  315,   26,  537],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,   21,    4,    4],\n",
            "        [ 586,   38,    9,  ...,  106,   34, 1093],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([29, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [105,  18,  18,  ...,   8,   5,   5],\n",
            "        [538,  26,  26,  ..., 364,  70,  26],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 176,   16,   16,  ...,    4,    4,    4],\n",
            "        [  17,   24,   24,  ..., 1197,   24,   34],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([33, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [ 5,  5,  8,  ...,  5,  8, 18],\n",
            "        [25, 13, 36,  ..., 13, 16, 73],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "trg: (torch.Size([35, 128])): tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [33,  4, 38,  ...,  4,  4, 16],\n",
            "        [ 8,  9, 12,  ...,  9, 14, 19],\n",
            "        ...,\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 1,  1,  1,  ...,  1,  1,  1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([32, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 43,  18,   5,  ...,  18,  43,  18],\n",
            "        [ 30,  45,  13,  ..., 103,  80,  25],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([31, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [681,  16,   4,  ...,  16,  48,  16],\n",
            "        [  9,  50,   9,  ...,  53, 127, 104],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,   18,  ...,    5,    8,    5],\n",
            "        [ 165,   25,   30,  ...,   13,    0,    0],\n",
            "        ...,\n",
            "        [   1,    1, 4278,  ...,    1,    1,    1],\n",
            "        [   1,    1,    4,  ...,    1,    1,    1],\n",
            "        [   1,    1,    3,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   33,   16,  ...,    4,    4,    4],\n",
            "        [ 120,    6,   30,  ...,    9, 2201,  267],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([38, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 59,   5,   5,  ...,   5,   5,  18],\n",
            "        [  6,  25, 738,  ...,  13,  49, 692],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([37, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    4,    4,   16],\n",
            "        [ 104,   33,  237,  ...,    9,  388,  133],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ..., 2602,    1,    1],\n",
            "        [   1,    1,    1,  ...,    5,    1,    1],\n",
            "        [   1,    1,    1,  ...,    3,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    8,  ...,    5,    5,    5],\n",
            "        [  13,   36,   16,  ..., 1863,   25,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([30, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,   46,  ...,    4,    4,    4],\n",
            "        [   9,   38,  120,  ..., 1846,   33,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([25, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [ 727,    5,    8,  ...,    5,    8,    5],\n",
            "        [1426,   26,   16,  ...,   13,   36,   66],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [521,   4,   4,  ..., 209,   4,   4],\n",
            "        [572,  24,  14,  ..., 174,  38,  24],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([26, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,   5,  ...,   5,   8,   5],\n",
            "        [  0,  36,  70,  ...,  70, 582,  66],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([27, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    4,    4,    4],\n",
            "        [5647,   38,   53,  ...,   53,  642,   53],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([27, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  8,   5,  76,  ...,   5, 416,   5],\n",
            "        [ 16, 538,  41,  ...,  13, 228, 942],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4, 113,  ...,   4, 176,   4],\n",
            "        [ 14, 648,  19,  ...,   9,  10, 161],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,   18,  ...,    5,  537,    5],\n",
            "        [ 452, 3133,  241,  ..., 5009,   57,   25],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,   16,  ...,    4,  660,    4],\n",
            "        [ 174, 2254, 3264,  ...,  135,  128,   33],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([25, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   8,  76,  ...,   5, 413,  18],\n",
            "        [  0,  16, 315,  ..., 241,  41,   0],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([28, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,  176,  ...,    4,  457, 1254],\n",
            "        [ 188,   14,   17,  ...,  323,   19,   15],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([30, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,  73,  ...,  15,  18,   5],\n",
            "        [ 13,  13, 137,  ..., 717,  30, 116],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,  19,  ...,  48,  16,   4],\n",
            "        [  9,   9,  17,  ...,  30,  30,  38],\n",
            "        ...,\n",
            "        [  1,   1,   1,  ..., 231,   1,   1],\n",
            "        [  1,   1,   1,  ...,   5,   1,   1],\n",
            "        [  1,   1,   1,  ...,   3,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0.5\n",
            "src (torch.Size([11, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  5,   5,   5,  ...,  26,  65,   5],\n",
            "        [ 13,  13,  13,  ...,  68, 137,  13],\n",
            "        ...,\n",
            "        [588,  91,  14,  ...,   1,   1,   1],\n",
            "        [  4,   4, 714,  ...,   1,   1,   1],\n",
            "        [  3,   3,   3,  ...,   1,   1,   1]], device='cuda:0')\n",
            "trg: (torch.Size([13, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,  34, 196,   4],\n",
            "        [  9,   9,   9,  ..., 169,  17,   9],\n",
            "        ...,\n",
            "        [  3,   3,   3,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "src (torch.Size([13, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  54,   18,    5,  ...,    5,   30,   32],\n",
            "        [3992,   54,  518,  ...,   66,    7, 1964],\n",
            "        ...,\n",
            "        [   4,   34,    4,  ...,    3,    3,    3],\n",
            "        [   3,    3,    3,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([13, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  19,   16,    4,  ...,    4,   30,   35],\n",
            "        [1581,   19,    9,  ...,   53,   22,    6],\n",
            "        ...,\n",
            "        [   5,  142,    5,  ...,    3,    3,    3],\n",
            "        [   3,    3,    3,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "src (torch.Size([13, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    5,  ...,    8,   39,   32],\n",
            "        [ 173,    0, 1427,  ...,   36,   48,   21],\n",
            "        ...,\n",
            "        [   4,    4,    4,  ...,    4,    4,    4],\n",
            "        [   3,    3,    3,  ...,    3,    3,    3],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([16, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   21,    4,  ...,    4,  209,   35],\n",
            "        [  34, 2720, 1103,  ...,   38,   10,    8],\n",
            "        ...,\n",
            "        [   5,    5,    5,  ...,    1,    1,    1],\n",
            "        [   3,    3,    3,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "src (torch.Size([17, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,   80,   18,  ...,    5,    8,   18],\n",
            "        [  26,   10,  490,  ...,  502, 6787,   30],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([17, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,  127,    4,  ...,    4,    4,   16],\n",
            "        [  34,   11,  154,  ...,  510, 1909,   30],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    3,    3,    3],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "src (torch.Size([15, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    8,    5,  ...,    5,    5,    5],\n",
            "        [1586,   26,  298,  ...,   96,   49,   26],\n",
            "        ...,\n",
            "        [ 129,  169,   12,  ...,    4,    4,    4],\n",
            "        [   4,    4,    4,  ...,    3,    3,    3],\n",
            "        [   3,    3,    3,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([17, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4, 176,   4,  ...,   4,   4,   4],\n",
            "        [ 36,  10, 216,  ...,  24,  55,  34],\n",
            "        ...,\n",
            "        [126,  77, 576,  ...,   1,   1,   1],\n",
            "        [  5,   5,   5,  ...,   1,   1,   1],\n",
            "        [  3,   3,   3,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "src (torch.Size([17, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5,    5,    5,  ...,    5,    5,    5],\n",
            "        [  13,   13,   13,  ...,  194,  130,   26],\n",
            "        ...,\n",
            "        [7688,  617,    0,  ...,    4,    4,    3],\n",
            "        [   4,    4,    4,  ...,    3,    3,    1],\n",
            "        [   3,    3,    3,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([21, 128])): tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [  4,   4,   4,  ...,   4,  21,   4],\n",
            "        [  9,   9,   9,  ..., 180, 115,  34],\n",
            "        ...,\n",
            "        [  3,   3,   3,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1],\n",
            "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "src (torch.Size([24, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,   24,  ...,   15,   18,    5],\n",
            "        [  67, 1225,   25,  ...,  452,   65,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([26, 128])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,    4,    4,  ...,    7,   16,    4],\n",
            "        [  64, 2066,  409,  ...,  174,   63,    9],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "src (torch.Size([35, 118])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,    5,    5,  ...,    8,    5,    8],\n",
            "        [  26,   25, 6756,  ...,  582,   66,   16],\n",
            "        ...,\n",
            "        [   4,  220,    1,  ...,    1,    1,    1],\n",
            "        [   3,    4,    1,  ...,    1,    1,    1],\n",
            "        [   1,    3,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "trg: (torch.Size([34, 118])): tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   4,   32,    4,  ...,    4,    4,    4],\n",
            "        [  24, 1991,  161,  ...,  642,   24,   14],\n",
            "        ...,\n",
            "        [   1,    1, 1335,  ...,    1,    1,    1],\n",
            "        [   1,    1,    5,  ...,    1,    1,    1],\n",
            "        [   1,    1,    3,  ...,    1,    1,    1]], device='cuda:0')\n",
            "teacher_forcing_ratio: 0\n",
            "Epoch: 10 | Time: 1m 30s\n",
            "\tTrain Loss: 1.478 | Train PPL:   4.384\n",
            "\t Val. Loss: 3.320 |  Val. PPL:  27.654\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJMzN5ga7-H8"
      },
      "source": [
        "Finally, we test the model on the test set using these \"best\" parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRMQlE4t7-H8",
        "outputId": "e5a00831-b55f-4990-d2f6-9407dd920e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Test Loss: 3.179 | Test PPL:  24.027 |\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('tut3-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8HLQCHK7-H8"
      },
      "source": [
        "We've improved on the previous model, but this came at the cost of doubling the training time.\n",
        "\n",
        "In the next notebook, we'll be using the same architecture but using a few tricks that are applicable to all RNN architectures - packed padded sequences and masking. We'll also implement code which will allow us to look at what words in the input the RNN is paying attention to when decoding the output."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
